{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sl\n",
    "import scipy as sp\n",
    "import seaborn as sb\n",
    "from matplotlib import pyplot as plt\n",
    "import oct2py as oclib\n",
    "import numpy as np\n",
    "import matplotlib as mp\n",
    "import statsmodels.api as sm\n",
    "from scipy.linalg import solve, eig\n",
    "import plotly.graph_objects as go\n",
    "from dash import dash_table\n",
    "from statsmodels.sandbox.regression.gmm import IV2SLS \n",
    "# There is a package named IV2SLS in Python. Do not use this package! The exogenous explanatory variables must\n",
    "# be entered as instruments. So it gives wrong answers\n",
    "from statsmodels.sandbox.regression.gmm import GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\oscar\\Downloads\\dataset_lm.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dependent Var</th>\n",
       "      <th>Explanatory Var #1</th>\n",
       "      <th>Explanatory Var #2</th>\n",
       "      <th>Explanatory Var #3</th>\n",
       "      <th>Explanatory Var #4</th>\n",
       "      <th>Explanatory Var #5</th>\n",
       "      <th>Explanatory Var #6</th>\n",
       "      <th>Explanatory Var #7</th>\n",
       "      <th>Explanatory Var #8</th>\n",
       "      <th>Explanatory Var #9</th>\n",
       "      <th>Explanatory Var #10</th>\n",
       "      <th>Explanatory Var #11</th>\n",
       "      <th>Explanatory Var #12</th>\n",
       "      <th>Explanatory Var #13</th>\n",
       "      <th>Explanatory Var #14</th>\n",
       "      <th>Explanatory Var #15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>422.000000</td>\n",
       "      <td>422.000000</td>\n",
       "      <td>422.000000</td>\n",
       "      <td>422.000000</td>\n",
       "      <td>422.000000</td>\n",
       "      <td>422.000000</td>\n",
       "      <td>422.000000</td>\n",
       "      <td>422.000000</td>\n",
       "      <td>422.000000</td>\n",
       "      <td>422.000000</td>\n",
       "      <td>422.000000</td>\n",
       "      <td>422.000000</td>\n",
       "      <td>422.000000</td>\n",
       "      <td>422.000000</td>\n",
       "      <td>422.000000</td>\n",
       "      <td>422.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>67.838396</td>\n",
       "      <td>7.762058</td>\n",
       "      <td>59.725134</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-16.078411</td>\n",
       "      <td>50.133715</td>\n",
       "      <td>10.420808</td>\n",
       "      <td>61.887309</td>\n",
       "      <td>1.566351</td>\n",
       "      <td>-24.511691</td>\n",
       "      <td>49.728665</td>\n",
       "      <td>7.740874</td>\n",
       "      <td>60.765794</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-16.673762</td>\n",
       "      <td>50.066901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>25.676960</td>\n",
       "      <td>7.013243</td>\n",
       "      <td>9.579112</td>\n",
       "      <td>0.500593</td>\n",
       "      <td>8.111197</td>\n",
       "      <td>6.975674</td>\n",
       "      <td>11.520725</td>\n",
       "      <td>14.819969</td>\n",
       "      <td>1.115260</td>\n",
       "      <td>8.500500</td>\n",
       "      <td>6.910690</td>\n",
       "      <td>7.102714</td>\n",
       "      <td>9.525835</td>\n",
       "      <td>0.500593</td>\n",
       "      <td>8.106466</td>\n",
       "      <td>6.794584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.997183</td>\n",
       "      <td>-4.832834</td>\n",
       "      <td>44.124858</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-29.774797</td>\n",
       "      <td>30.009511</td>\n",
       "      <td>-9.828552</td>\n",
       "      <td>34.093154</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-39.979696</td>\n",
       "      <td>26.436407</td>\n",
       "      <td>-4.949728</td>\n",
       "      <td>44.158200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-29.750628</td>\n",
       "      <td>32.118882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>49.482037</td>\n",
       "      <td>1.720182</td>\n",
       "      <td>51.617692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-23.792637</td>\n",
       "      <td>45.423422</td>\n",
       "      <td>-0.174835</td>\n",
       "      <td>49.952772</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-32.037707</td>\n",
       "      <td>45.283603</td>\n",
       "      <td>1.838210</td>\n",
       "      <td>52.849792</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-23.797763</td>\n",
       "      <td>45.825931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>66.780110</td>\n",
       "      <td>7.905455</td>\n",
       "      <td>59.735139</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-15.875481</td>\n",
       "      <td>50.093602</td>\n",
       "      <td>10.422513</td>\n",
       "      <td>62.554591</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-23.767548</td>\n",
       "      <td>49.842746</td>\n",
       "      <td>8.055297</td>\n",
       "      <td>60.773906</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-17.373619</td>\n",
       "      <td>50.038667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>86.801496</td>\n",
       "      <td>13.684104</td>\n",
       "      <td>67.870073</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-9.185191</td>\n",
       "      <td>54.896583</td>\n",
       "      <td>21.059713</td>\n",
       "      <td>74.441216</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>-17.419390</td>\n",
       "      <td>54.576381</td>\n",
       "      <td>14.020396</td>\n",
       "      <td>69.262757</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-9.627544</td>\n",
       "      <td>54.962602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>133.384795</td>\n",
       "      <td>19.973331</td>\n",
       "      <td>76.973576</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-2.060708</td>\n",
       "      <td>70.365951</td>\n",
       "      <td>29.994610</td>\n",
       "      <td>86.895006</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>-10.129522</td>\n",
       "      <td>68.201681</td>\n",
       "      <td>19.992891</td>\n",
       "      <td>76.639179</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-2.003168</td>\n",
       "      <td>69.147818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Dependent Var  Explanatory Var #1  Explanatory Var #2  \\\n",
       "count     422.000000          422.000000          422.000000   \n",
       "mean       67.838396            7.762058           59.725134   \n",
       "std        25.676960            7.013243            9.579112   \n",
       "min        -2.997183           -4.832834           44.124858   \n",
       "25%        49.482037            1.720182           51.617692   \n",
       "50%        66.780110            7.905455           59.735139   \n",
       "75%        86.801496           13.684104           67.870073   \n",
       "max       133.384795           19.973331           76.973576   \n",
       "\n",
       "       Explanatory Var #3  Explanatory Var #4  Explanatory Var #5  \\\n",
       "count          422.000000          422.000000          422.000000   \n",
       "mean             0.500000          -16.078411           50.133715   \n",
       "std              0.500593            8.111197            6.975674   \n",
       "min              0.000000          -29.774797           30.009511   \n",
       "25%              0.000000          -23.792637           45.423422   \n",
       "50%              0.500000          -15.875481           50.093602   \n",
       "75%              1.000000           -9.185191           54.896583   \n",
       "max              1.000000           -2.060708           70.365951   \n",
       "\n",
       "       Explanatory Var #6  Explanatory Var #7  Explanatory Var #8  \\\n",
       "count          422.000000          422.000000          422.000000   \n",
       "mean            10.420808           61.887309            1.566351   \n",
       "std             11.520725           14.819969            1.115260   \n",
       "min             -9.828552           34.093154            0.000000   \n",
       "25%             -0.174835           49.952772            1.000000   \n",
       "50%             10.422513           62.554591            2.000000   \n",
       "75%             21.059713           74.441216            3.000000   \n",
       "max             29.994610           86.895006            3.000000   \n",
       "\n",
       "       Explanatory Var #9  Explanatory Var #10  Explanatory Var #11  \\\n",
       "count          422.000000           422.000000           422.000000   \n",
       "mean           -24.511691            49.728665             7.740874   \n",
       "std              8.500500             6.910690             7.102714   \n",
       "min            -39.979696            26.436407            -4.949728   \n",
       "25%            -32.037707            45.283603             1.838210   \n",
       "50%            -23.767548            49.842746             8.055297   \n",
       "75%            -17.419390            54.576381            14.020396   \n",
       "max            -10.129522            68.201681            19.992891   \n",
       "\n",
       "       Explanatory Var #12  Explanatory Var #13  Explanatory Var #14  \\\n",
       "count           422.000000           422.000000           422.000000   \n",
       "mean             60.765794             0.500000           -16.673762   \n",
       "std               9.525835             0.500593             8.106466   \n",
       "min              44.158200             0.000000           -29.750628   \n",
       "25%              52.849792             0.000000           -23.797763   \n",
       "50%              60.773906             0.500000           -17.373619   \n",
       "75%              69.262757             1.000000            -9.627544   \n",
       "max              76.639179             1.000000            -2.003168   \n",
       "\n",
       "       Explanatory Var #15  \n",
       "count           422.000000  \n",
       "mean             50.066901  \n",
       "std               6.794584  \n",
       "min              32.118882  \n",
       "25%              45.825931  \n",
       "50%              50.038667  \n",
       "75%              54.962602  \n",
       "max              69.147818  "
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Dependent Var', 'Explanatory Var #1', 'Explanatory Var #2',\n",
       "       'Explanatory Var #3', 'Explanatory Var #4', 'Explanatory Var #5',\n",
       "       'Explanatory Var #6', 'Explanatory Var #7', 'Explanatory Var #8',\n",
       "       'Explanatory Var #9', 'Explanatory Var #10', 'Explanatory Var #11',\n",
       "       'Explanatory Var #12', 'Explanatory Var #13', 'Explanatory Var #14',\n",
       "       'Explanatory Var #15'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"Dependent Var\"])\n",
    "y = df[\"Dependent Var\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>      <td>Dependent Var</td>  <th>  R-squared (uncentered):</th>      <td>   0.999</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.999</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>4.509e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 28 Oct 2023</td> <th>  Prob (F-statistic):</th>           <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>19:41:46</td>     <th>  Log-Likelihood:    </th>          <td> -841.76</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   422</td>      <th>  AIC:               </th>          <td>   1714.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   407</td>      <th>  BIC:               </th>          <td>   1774.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    15</td>      <th>                     </th>              <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>              <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #1</th>  <td>    1.3078</td> <td>    0.013</td> <td>  102.159</td> <td> 0.000</td> <td>    1.283</td> <td>    1.333</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #2</th>  <td>    1.7667</td> <td>    0.009</td> <td>  203.101</td> <td> 0.000</td> <td>    1.750</td> <td>    1.784</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #3</th>  <td>    6.6083</td> <td>    0.177</td> <td>   37.232</td> <td> 0.000</td> <td>    6.259</td> <td>    6.957</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #4</th>  <td>    2.0725</td> <td>    0.011</td> <td>  189.896</td> <td> 0.000</td> <td>    2.051</td> <td>    2.094</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #5</th>  <td>   -0.7776</td> <td>    0.011</td> <td>  -68.372</td> <td> 0.000</td> <td>   -0.800</td> <td>   -0.755</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #6</th>  <td>    0.0124</td> <td>    0.008</td> <td>    1.595</td> <td> 0.111</td> <td>   -0.003</td> <td>    0.028</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #7</th>  <td>    0.0286</td> <td>    0.006</td> <td>    4.890</td> <td> 0.000</td> <td>    0.017</td> <td>    0.040</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #8</th>  <td>    0.3510</td> <td>    0.080</td> <td>    4.398</td> <td> 0.000</td> <td>    0.194</td> <td>    0.508</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #9</th>  <td>   -0.0293</td> <td>    0.010</td> <td>   -2.838</td> <td> 0.005</td> <td>   -0.050</td> <td>   -0.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #10</th> <td>    0.1292</td> <td>    0.011</td> <td>   11.409</td> <td> 0.000</td> <td>    0.107</td> <td>    0.152</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #11</th> <td>    0.0145</td> <td>    0.013</td> <td>    1.152</td> <td> 0.250</td> <td>   -0.010</td> <td>    0.039</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #12</th> <td>    0.0752</td> <td>    0.009</td> <td>    8.698</td> <td> 0.000</td> <td>    0.058</td> <td>    0.092</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #13</th> <td>    0.7414</td> <td>    0.177</td> <td>    4.198</td> <td> 0.000</td> <td>    0.394</td> <td>    1.089</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #14</th> <td>   -0.0218</td> <td>    0.011</td> <td>   -1.974</td> <td> 0.049</td> <td>   -0.043</td> <td>-8.61e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #15</th> <td>    0.1212</td> <td>    0.012</td> <td>   10.324</td> <td> 0.000</td> <td>    0.098</td> <td>    0.144</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.087</td> <th>  Durbin-Watson:     </th> <td>   1.875</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.957</td> <th>  Jarque-Bera (JB):  </th> <td>   0.188</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.004</td> <th>  Prob(JB):          </th> <td>   0.910</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.897</td> <th>  Cond. No.          </th> <td>    287.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] R² is computed without centering (uncentered) since the model does not contain a constant.<br/>[2] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}       &  Dependent Var   & \\textbf{  R-squared (uncentered):}      &     0.999   \\\\\n",
       "\\textbf{Model:}               &       OLS        & \\textbf{  Adj. R-squared (uncentered):} &     0.999   \\\\\n",
       "\\textbf{Method:}              &  Least Squares   & \\textbf{  F-statistic:       }          & 4.509e+04   \\\\\n",
       "\\textbf{Date:}                & Sat, 28 Oct 2023 & \\textbf{  Prob (F-statistic):}          &     0.00    \\\\\n",
       "\\textbf{Time:}                &     19:41:46     & \\textbf{  Log-Likelihood:    }          &   -841.76   \\\\\n",
       "\\textbf{No. Observations:}    &         422      & \\textbf{  AIC:               }          &     1714.   \\\\\n",
       "\\textbf{Df Residuals:}        &         407      & \\textbf{  BIC:               }          &     1774.   \\\\\n",
       "\\textbf{Df Model:}            &          15      & \\textbf{                     }          &             \\\\\n",
       "\\textbf{Covariance Type:}     &    nonrobust     & \\textbf{                     }          &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                              & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Explanatory Var \\#1}  &       1.3078  &        0.013     &   102.159  &         0.000        &        1.283    &        1.333     \\\\\n",
       "\\textbf{Explanatory Var \\#2}  &       1.7667  &        0.009     &   203.101  &         0.000        &        1.750    &        1.784     \\\\\n",
       "\\textbf{Explanatory Var \\#3}  &       6.6083  &        0.177     &    37.232  &         0.000        &        6.259    &        6.957     \\\\\n",
       "\\textbf{Explanatory Var \\#4}  &       2.0725  &        0.011     &   189.896  &         0.000        &        2.051    &        2.094     \\\\\n",
       "\\textbf{Explanatory Var \\#5}  &      -0.7776  &        0.011     &   -68.372  &         0.000        &       -0.800    &       -0.755     \\\\\n",
       "\\textbf{Explanatory Var \\#6}  &       0.0124  &        0.008     &     1.595  &         0.111        &       -0.003    &        0.028     \\\\\n",
       "\\textbf{Explanatory Var \\#7}  &       0.0286  &        0.006     &     4.890  &         0.000        &        0.017    &        0.040     \\\\\n",
       "\\textbf{Explanatory Var \\#8}  &       0.3510  &        0.080     &     4.398  &         0.000        &        0.194    &        0.508     \\\\\n",
       "\\textbf{Explanatory Var \\#9}  &      -0.0293  &        0.010     &    -2.838  &         0.005        &       -0.050    &       -0.009     \\\\\n",
       "\\textbf{Explanatory Var \\#10} &       0.1292  &        0.011     &    11.409  &         0.000        &        0.107    &        0.152     \\\\\n",
       "\\textbf{Explanatory Var \\#11} &       0.0145  &        0.013     &     1.152  &         0.250        &       -0.010    &        0.039     \\\\\n",
       "\\textbf{Explanatory Var \\#12} &       0.0752  &        0.009     &     8.698  &         0.000        &        0.058    &        0.092     \\\\\n",
       "\\textbf{Explanatory Var \\#13} &       0.7414  &        0.177     &     4.198  &         0.000        &        0.394    &        1.089     \\\\\n",
       "\\textbf{Explanatory Var \\#14} &      -0.0218  &        0.011     &    -1.974  &         0.049        &       -0.043    &    -8.61e-05     \\\\\n",
       "\\textbf{Explanatory Var \\#15} &       0.1212  &        0.012     &    10.324  &         0.000        &        0.098    &        0.144     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  0.087 & \\textbf{  Durbin-Watson:     } &    1.875  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.957 & \\textbf{  Jarque-Bera (JB):  } &    0.188  \\\\\n",
       "\\textbf{Skew:}          & -0.004 & \\textbf{  Prob(JB):          } &    0.910  \\\\\n",
       "\\textbf{Kurtosis:}      &  2.897 & \\textbf{  Cond. No.          } &     287.  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] R² is computed without centering (uncentered) since the model does not contain a constant. \\newline\n",
       " [2] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 OLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:          Dependent Var   R-squared (uncentered):                   0.999\n",
       "Model:                            OLS   Adj. R-squared (uncentered):              0.999\n",
       "Method:                 Least Squares   F-statistic:                          4.509e+04\n",
       "Date:                Sat, 28 Oct 2023   Prob (F-statistic):                        0.00\n",
       "Time:                        19:41:46   Log-Likelihood:                         -841.76\n",
       "No. Observations:                 422   AIC:                                      1714.\n",
       "Df Residuals:                     407   BIC:                                      1774.\n",
       "Df Model:                          15                                                  \n",
       "Covariance Type:            nonrobust                                                  \n",
       "=======================================================================================\n",
       "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------------\n",
       "Explanatory Var #1      1.3078      0.013    102.159      0.000       1.283       1.333\n",
       "Explanatory Var #2      1.7667      0.009    203.101      0.000       1.750       1.784\n",
       "Explanatory Var #3      6.6083      0.177     37.232      0.000       6.259       6.957\n",
       "Explanatory Var #4      2.0725      0.011    189.896      0.000       2.051       2.094\n",
       "Explanatory Var #5     -0.7776      0.011    -68.372      0.000      -0.800      -0.755\n",
       "Explanatory Var #6      0.0124      0.008      1.595      0.111      -0.003       0.028\n",
       "Explanatory Var #7      0.0286      0.006      4.890      0.000       0.017       0.040\n",
       "Explanatory Var #8      0.3510      0.080      4.398      0.000       0.194       0.508\n",
       "Explanatory Var #9     -0.0293      0.010     -2.838      0.005      -0.050      -0.009\n",
       "Explanatory Var #10     0.1292      0.011     11.409      0.000       0.107       0.152\n",
       "Explanatory Var #11     0.0145      0.013      1.152      0.250      -0.010       0.039\n",
       "Explanatory Var #12     0.0752      0.009      8.698      0.000       0.058       0.092\n",
       "Explanatory Var #13     0.7414      0.177      4.198      0.000       0.394       1.089\n",
       "Explanatory Var #14    -0.0218      0.011     -1.974      0.049      -0.043   -8.61e-05\n",
       "Explanatory Var #15     0.1212      0.012     10.324      0.000       0.098       0.144\n",
       "==============================================================================\n",
       "Omnibus:                        0.087   Durbin-Watson:                   1.875\n",
       "Prob(Omnibus):                  0.957   Jarque-Bera (JB):                0.188\n",
       "Skew:                          -0.004   Prob(JB):                        0.910\n",
       "Kurtosis:                       2.897   Cond. No.                         287.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
       "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ols = sm.OLS(y, X).fit()\n",
    "model_ols.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No intercept, so add constant is needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>      <td>Dependent Var</td>  <th>  R-squared:         </th>  <td>   1.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   1.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>5.506e+30</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 28 Oct 2023</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>19:41:46</td>     <th>  Log-Likelihood:    </th>  <td>  12271.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   422</td>      <th>  AIC:               </th> <td>-2.451e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   406</td>      <th>  BIC:               </th> <td>-2.445e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    15</td>      <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>              <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>               <td>   32.0000</td> <td> 5.08e-14</td> <td>  6.3e+14</td> <td> 0.000</td> <td>   32.000</td> <td>   32.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #1</th>  <td>    1.3000</td> <td>  4.1e-16</td> <td> 3.17e+15</td> <td> 0.000</td> <td>    1.300</td> <td>    1.300</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #2</th>  <td>    1.7000</td> <td> 2.98e-16</td> <td> 5.71e+15</td> <td> 0.000</td> <td>    1.700</td> <td>    1.700</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #3</th>  <td>    6.2000</td> <td> 5.72e-15</td> <td> 1.08e+15</td> <td> 0.000</td> <td>    6.200</td> <td>    6.200</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #4</th>  <td>    2.1000</td> <td> 3.52e-16</td> <td> 5.96e+15</td> <td> 0.000</td> <td>    2.100</td> <td>    2.100</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #5</th>  <td>   -0.9000</td> <td> 4.13e-16</td> <td>-2.18e+15</td> <td> 0.000</td> <td>   -0.900</td> <td>   -0.900</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #6</th>  <td> -9.86e-16</td> <td> 2.49e-16</td> <td>   -3.959</td> <td> 0.000</td> <td>-1.48e-15</td> <td>-4.96e-16</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #7</th>  <td>-7.268e-16</td> <td> 1.92e-16</td> <td>   -3.778</td> <td> 0.000</td> <td>-1.11e-15</td> <td>-3.49e-16</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #8</th>  <td>-8.604e-16</td> <td> 2.61e-15</td> <td>   -0.329</td> <td> 0.742</td> <td>   -6e-15</td> <td> 4.28e-15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #9</th>  <td>  1.11e-15</td> <td> 3.34e-16</td> <td>    3.322</td> <td> 0.001</td> <td> 4.53e-16</td> <td> 1.77e-15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #10</th> <td>-5.438e-16</td> <td> 4.17e-16</td> <td>   -1.305</td> <td> 0.193</td> <td>-1.36e-15</td> <td> 2.75e-16</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #11</th> <td> 7.494e-16</td> <td> 4.03e-16</td> <td>    1.860</td> <td> 0.064</td> <td>-4.26e-17</td> <td> 1.54e-15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #12</th> <td>-4.111e-16</td> <td> 3.01e-16</td> <td>   -1.364</td> <td> 0.173</td> <td>   -1e-15</td> <td> 1.81e-16</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #13</th> <td>-2.201e-14</td> <td> 5.77e-15</td> <td>   -3.811</td> <td> 0.000</td> <td>-3.34e-14</td> <td>-1.07e-14</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #14</th> <td>  1.69e-15</td> <td> 3.55e-16</td> <td>    4.768</td> <td> 0.000</td> <td> 9.94e-16</td> <td> 2.39e-15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #15</th> <td>-8.916e-16</td> <td> 4.22e-16</td> <td>   -2.112</td> <td> 0.035</td> <td>-1.72e-15</td> <td>-6.17e-17</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.278</td> <th>  Durbin-Watson:     </th> <td>   0.806</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.528</td> <th>  Jarque-Bera (JB):  </th> <td>   1.327</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.131</td> <th>  Prob(JB):          </th> <td>   0.515</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.918</td> <th>  Cond. No.          </th> <td>2.55e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.55e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}       &  Dependent Var   & \\textbf{  R-squared:         } &     1.000   \\\\\n",
       "\\textbf{Model:}               &       OLS        & \\textbf{  Adj. R-squared:    } &     1.000   \\\\\n",
       "\\textbf{Method:}              &  Least Squares   & \\textbf{  F-statistic:       } & 5.506e+30   \\\\\n",
       "\\textbf{Date:}                & Sat, 28 Oct 2023 & \\textbf{  Prob (F-statistic):} &     0.00    \\\\\n",
       "\\textbf{Time:}                &     19:41:46     & \\textbf{  Log-Likelihood:    } &    12271.   \\\\\n",
       "\\textbf{No. Observations:}    &         422      & \\textbf{  AIC:               } & -2.451e+04  \\\\\n",
       "\\textbf{Df Residuals:}        &         406      & \\textbf{  BIC:               } & -2.445e+04  \\\\\n",
       "\\textbf{Df Model:}            &          15      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}     &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                              & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const}                &      32.0000  &     5.08e-14     &   6.3e+14  &         0.000        &       32.000    &       32.000     \\\\\n",
       "\\textbf{Explanatory Var \\#1}  &       1.3000  &      4.1e-16     &  3.17e+15  &         0.000        &        1.300    &        1.300     \\\\\n",
       "\\textbf{Explanatory Var \\#2}  &       1.7000  &     2.98e-16     &  5.71e+15  &         0.000        &        1.700    &        1.700     \\\\\n",
       "\\textbf{Explanatory Var \\#3}  &       6.2000  &     5.72e-15     &  1.08e+15  &         0.000        &        6.200    &        6.200     \\\\\n",
       "\\textbf{Explanatory Var \\#4}  &       2.1000  &     3.52e-16     &  5.96e+15  &         0.000        &        2.100    &        2.100     \\\\\n",
       "\\textbf{Explanatory Var \\#5}  &      -0.9000  &     4.13e-16     & -2.18e+15  &         0.000        &       -0.900    &       -0.900     \\\\\n",
       "\\textbf{Explanatory Var \\#6}  &    -9.86e-16  &     2.49e-16     &    -3.959  &         0.000        &    -1.48e-15    &    -4.96e-16     \\\\\n",
       "\\textbf{Explanatory Var \\#7}  &   -7.268e-16  &     1.92e-16     &    -3.778  &         0.000        &    -1.11e-15    &    -3.49e-16     \\\\\n",
       "\\textbf{Explanatory Var \\#8}  &   -8.604e-16  &     2.61e-15     &    -0.329  &         0.742        &       -6e-15    &     4.28e-15     \\\\\n",
       "\\textbf{Explanatory Var \\#9}  &     1.11e-15  &     3.34e-16     &     3.322  &         0.001        &     4.53e-16    &     1.77e-15     \\\\\n",
       "\\textbf{Explanatory Var \\#10} &   -5.438e-16  &     4.17e-16     &    -1.305  &         0.193        &    -1.36e-15    &     2.75e-16     \\\\\n",
       "\\textbf{Explanatory Var \\#11} &    7.494e-16  &     4.03e-16     &     1.860  &         0.064        &    -4.26e-17    &     1.54e-15     \\\\\n",
       "\\textbf{Explanatory Var \\#12} &   -4.111e-16  &     3.01e-16     &    -1.364  &         0.173        &       -1e-15    &     1.81e-16     \\\\\n",
       "\\textbf{Explanatory Var \\#13} &   -2.201e-14  &     5.77e-15     &    -3.811  &         0.000        &    -3.34e-14    &    -1.07e-14     \\\\\n",
       "\\textbf{Explanatory Var \\#14} &     1.69e-15  &     3.55e-16     &     4.768  &         0.000        &     9.94e-16    &     2.39e-15     \\\\\n",
       "\\textbf{Explanatory Var \\#15} &   -8.916e-16  &     4.22e-16     &    -2.112  &         0.035        &    -1.72e-15    &    -6.17e-17     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  1.278 & \\textbf{  Durbin-Watson:     } &    0.806  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.528 & \\textbf{  Jarque-Bera (JB):  } &    1.327  \\\\\n",
       "\\textbf{Skew:}          & -0.131 & \\textbf{  Prob(JB):          } &    0.515  \\\\\n",
       "\\textbf{Kurtosis:}      &  2.918 & \\textbf{  Cond. No.          } & 2.55e+03  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 2.55e+03. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:          Dependent Var   R-squared:                       1.000\n",
       "Model:                            OLS   Adj. R-squared:                  1.000\n",
       "Method:                 Least Squares   F-statistic:                 5.506e+30\n",
       "Date:                Sat, 28 Oct 2023   Prob (F-statistic):               0.00\n",
       "Time:                        19:41:46   Log-Likelihood:                 12271.\n",
       "No. Observations:                 422   AIC:                        -2.451e+04\n",
       "Df Residuals:                     406   BIC:                        -2.445e+04\n",
       "Df Model:                          15                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=======================================================================================\n",
       "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------------\n",
       "const                  32.0000   5.08e-14    6.3e+14      0.000      32.000      32.000\n",
       "Explanatory Var #1      1.3000    4.1e-16   3.17e+15      0.000       1.300       1.300\n",
       "Explanatory Var #2      1.7000   2.98e-16   5.71e+15      0.000       1.700       1.700\n",
       "Explanatory Var #3      6.2000   5.72e-15   1.08e+15      0.000       6.200       6.200\n",
       "Explanatory Var #4      2.1000   3.52e-16   5.96e+15      0.000       2.100       2.100\n",
       "Explanatory Var #5     -0.9000   4.13e-16  -2.18e+15      0.000      -0.900      -0.900\n",
       "Explanatory Var #6   -9.86e-16   2.49e-16     -3.959      0.000   -1.48e-15   -4.96e-16\n",
       "Explanatory Var #7  -7.268e-16   1.92e-16     -3.778      0.000   -1.11e-15   -3.49e-16\n",
       "Explanatory Var #8  -8.604e-16   2.61e-15     -0.329      0.742      -6e-15    4.28e-15\n",
       "Explanatory Var #9    1.11e-15   3.34e-16      3.322      0.001    4.53e-16    1.77e-15\n",
       "Explanatory Var #10 -5.438e-16   4.17e-16     -1.305      0.193   -1.36e-15    2.75e-16\n",
       "Explanatory Var #11  7.494e-16   4.03e-16      1.860      0.064   -4.26e-17    1.54e-15\n",
       "Explanatory Var #12 -4.111e-16   3.01e-16     -1.364      0.173      -1e-15    1.81e-16\n",
       "Explanatory Var #13 -2.201e-14   5.77e-15     -3.811      0.000   -3.34e-14   -1.07e-14\n",
       "Explanatory Var #14   1.69e-15   3.55e-16      4.768      0.000    9.94e-16    2.39e-15\n",
       "Explanatory Var #15 -8.916e-16   4.22e-16     -2.112      0.035   -1.72e-15   -6.17e-17\n",
       "==============================================================================\n",
       "Omnibus:                        1.278   Durbin-Watson:                   0.806\n",
       "Prob(Omnibus):                  0.528   Jarque-Bera (JB):                1.327\n",
       "Skew:                          -0.131   Prob(JB):                        0.515\n",
       "Kurtosis:                       2.918   Cond. No.                     2.55e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 2.55e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_updated = sm.add_constant(X)\n",
    "model_updated = sm.OLS(y,X_updated).fit()\n",
    "model_updated.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the residual of the ols model\n",
    "residuals = model_updated.resid\n",
    "\n",
    "# Calculate the standard deviation of the residuals\n",
    "std_deviation = np.std(residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ols = model_updated.predict(X_updated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     -5.684342e-14\n",
       "1     -5.684342e-14\n",
       "2      1.421085e-14\n",
       "3     -1.207923e-13\n",
       "4     -2.842171e-14\n",
       "           ...     \n",
       "417   -5.684342e-14\n",
       "418   -3.552714e-14\n",
       "419   -4.263256e-14\n",
       "420    7.105427e-15\n",
       "421   -7.815970e-14\n",
       "Length: 422, dtype: float64"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Deviation of Residuals: 3.658463587473027e-14\n",
      "Autocorrelation at Lag 1: 0.025670176340677635\n",
      "Autocorrelation at Lag 2: -0.025167006405992433\n",
      "Autocorrelation at Lag 3: 0.004647515690314895\n"
     ]
    }
   ],
   "source": [
    "# Calculate the autocorrelation for the first three lags\n",
    "lags = 3\n",
    "autocorr_lag1 = residuals.autocorr(lag=1)  # Autocorrelation at lag 1\n",
    "autocorr_lag2 = residuals.autocorr(lag=2)  # Autocorrelation at lag 2\n",
    "autocorr_lag3 = residuals.autocorr(lag=3)  # Autocorrelation at lag 3\n",
    "\n",
    "print(\"Standard Deviation of Residuals:\", std_deviation)\n",
    "print(\"Autocorrelation at Lag 1:\", autocorr_lag1)\n",
    "print(\"Autocorrelation at Lag 2:\", autocorr_lag2)\n",
    "print(\"Autocorrelation at Lag 3:\", autocorr_lag3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>GLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>      <td>Dependent Var</td>  <th>  R-squared:         </th>  <td>   1.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>GLS</td>       <th>  Adj. R-squared:    </th>  <td>   1.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>8.930e+30</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 28 Oct 2023</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>19:41:47</td>     <th>  Log-Likelihood:    </th>  <td>  12374.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   422</td>      <th>  AIC:               </th> <td>-2.472e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   406</td>      <th>  BIC:               </th> <td>-2.465e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    15</td>      <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>              <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>               <td>   32.0000</td> <td> 3.98e-14</td> <td> 8.05e+14</td> <td> 0.000</td> <td>   32.000</td> <td>   32.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #1</th>  <td>    1.3000</td> <td> 3.21e-16</td> <td> 4.05e+15</td> <td> 0.000</td> <td>    1.300</td> <td>    1.300</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #2</th>  <td>    1.7000</td> <td> 2.34e-16</td> <td> 7.27e+15</td> <td> 0.000</td> <td>    1.700</td> <td>    1.700</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #3</th>  <td>    6.2000</td> <td> 4.48e-15</td> <td> 1.38e+15</td> <td> 0.000</td> <td>    6.200</td> <td>    6.200</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #4</th>  <td>    2.1000</td> <td> 2.76e-16</td> <td>  7.6e+15</td> <td> 0.000</td> <td>    2.100</td> <td>    2.100</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #5</th>  <td>   -0.9000</td> <td> 3.24e-16</td> <td>-2.78e+15</td> <td> 0.000</td> <td>   -0.900</td> <td>   -0.900</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #6</th>  <td> 9.253e-16</td> <td> 1.95e-16</td> <td>    4.743</td> <td> 0.000</td> <td> 5.42e-16</td> <td> 1.31e-15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #7</th>  <td>-8.635e-16</td> <td> 1.51e-16</td> <td>   -5.719</td> <td> 0.000</td> <td>-1.16e-15</td> <td>-5.67e-16</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #8</th>  <td> 1.138e-15</td> <td> 2.05e-15</td> <td>    0.555</td> <td> 0.579</td> <td>-2.89e-15</td> <td> 5.17e-15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #9</th>  <td> 2.272e-15</td> <td> 2.62e-16</td> <td>    8.668</td> <td> 0.000</td> <td> 1.76e-15</td> <td> 2.79e-15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #10</th> <td>-2.119e-15</td> <td> 3.26e-16</td> <td>   -6.502</td> <td> 0.000</td> <td>-2.76e-15</td> <td>-1.48e-15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #11</th> <td>-1.166e-15</td> <td> 3.16e-16</td> <td>   -3.692</td> <td> 0.000</td> <td>-1.79e-15</td> <td>-5.45e-16</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #12</th> <td> -3.99e-16</td> <td> 2.36e-16</td> <td>   -1.693</td> <td> 0.091</td> <td>-8.62e-16</td> <td> 6.44e-17</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #13</th> <td>-2.198e-14</td> <td> 4.51e-15</td> <td>   -4.869</td> <td> 0.000</td> <td>-3.09e-14</td> <td>-1.31e-14</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #14</th> <td>-1.263e-15</td> <td> 2.77e-16</td> <td>   -4.555</td> <td> 0.000</td> <td>-1.81e-15</td> <td>-7.18e-16</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #15</th> <td>-4.163e-16</td> <td>  3.3e-16</td> <td>   -1.263</td> <td> 0.207</td> <td>-1.06e-15</td> <td> 2.32e-16</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 4.416</td> <th>  Durbin-Watson:     </th> <td>   1.919</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.110</td> <th>  Jarque-Bera (JB):  </th> <td>   4.297</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.246</td> <th>  Prob(JB):          </th> <td>   0.117</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.044</td> <th>  Cond. No.          </th> <td>2.53e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.53e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}       &  Dependent Var   & \\textbf{  R-squared:         } &     1.000   \\\\\n",
       "\\textbf{Model:}               &       GLS        & \\textbf{  Adj. R-squared:    } &     1.000   \\\\\n",
       "\\textbf{Method:}              &  Least Squares   & \\textbf{  F-statistic:       } & 8.930e+30   \\\\\n",
       "\\textbf{Date:}                & Sat, 28 Oct 2023 & \\textbf{  Prob (F-statistic):} &     0.00    \\\\\n",
       "\\textbf{Time:}                &     19:41:47     & \\textbf{  Log-Likelihood:    } &    12374.   \\\\\n",
       "\\textbf{No. Observations:}    &         422      & \\textbf{  AIC:               } & -2.472e+04  \\\\\n",
       "\\textbf{Df Residuals:}        &         406      & \\textbf{  BIC:               } & -2.465e+04  \\\\\n",
       "\\textbf{Df Model:}            &          15      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}     &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                              & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const}                &      32.0000  &     3.98e-14     &  8.05e+14  &         0.000        &       32.000    &       32.000     \\\\\n",
       "\\textbf{Explanatory Var \\#1}  &       1.3000  &     3.21e-16     &  4.05e+15  &         0.000        &        1.300    &        1.300     \\\\\n",
       "\\textbf{Explanatory Var \\#2}  &       1.7000  &     2.34e-16     &  7.27e+15  &         0.000        &        1.700    &        1.700     \\\\\n",
       "\\textbf{Explanatory Var \\#3}  &       6.2000  &     4.48e-15     &  1.38e+15  &         0.000        &        6.200    &        6.200     \\\\\n",
       "\\textbf{Explanatory Var \\#4}  &       2.1000  &     2.76e-16     &   7.6e+15  &         0.000        &        2.100    &        2.100     \\\\\n",
       "\\textbf{Explanatory Var \\#5}  &      -0.9000  &     3.24e-16     & -2.78e+15  &         0.000        &       -0.900    &       -0.900     \\\\\n",
       "\\textbf{Explanatory Var \\#6}  &    9.253e-16  &     1.95e-16     &     4.743  &         0.000        &     5.42e-16    &     1.31e-15     \\\\\n",
       "\\textbf{Explanatory Var \\#7}  &   -8.635e-16  &     1.51e-16     &    -5.719  &         0.000        &    -1.16e-15    &    -5.67e-16     \\\\\n",
       "\\textbf{Explanatory Var \\#8}  &    1.138e-15  &     2.05e-15     &     0.555  &         0.579        &    -2.89e-15    &     5.17e-15     \\\\\n",
       "\\textbf{Explanatory Var \\#9}  &    2.272e-15  &     2.62e-16     &     8.668  &         0.000        &     1.76e-15    &     2.79e-15     \\\\\n",
       "\\textbf{Explanatory Var \\#10} &   -2.119e-15  &     3.26e-16     &    -6.502  &         0.000        &    -2.76e-15    &    -1.48e-15     \\\\\n",
       "\\textbf{Explanatory Var \\#11} &   -1.166e-15  &     3.16e-16     &    -3.692  &         0.000        &    -1.79e-15    &    -5.45e-16     \\\\\n",
       "\\textbf{Explanatory Var \\#12} &    -3.99e-16  &     2.36e-16     &    -1.693  &         0.091        &    -8.62e-16    &     6.44e-17     \\\\\n",
       "\\textbf{Explanatory Var \\#13} &   -2.198e-14  &     4.51e-15     &    -4.869  &         0.000        &    -3.09e-14    &    -1.31e-14     \\\\\n",
       "\\textbf{Explanatory Var \\#14} &   -1.263e-15  &     2.77e-16     &    -4.555  &         0.000        &    -1.81e-15    &    -7.18e-16     \\\\\n",
       "\\textbf{Explanatory Var \\#15} &   -4.163e-16  &      3.3e-16     &    -1.263  &         0.207        &    -1.06e-15    &     2.32e-16     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  4.416 & \\textbf{  Durbin-Watson:     } &    1.919  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.110 & \\textbf{  Jarque-Bera (JB):  } &    4.297  \\\\\n",
       "\\textbf{Skew:}          &  0.246 & \\textbf{  Prob(JB):          } &    0.117  \\\\\n",
       "\\textbf{Kurtosis:}      &  3.044 & \\textbf{  Cond. No.          } & 2.53e+03  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{GLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 2.53e+03. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            GLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:          Dependent Var   R-squared:                       1.000\n",
       "Model:                            GLS   Adj. R-squared:                  1.000\n",
       "Method:                 Least Squares   F-statistic:                 8.930e+30\n",
       "Date:                Sat, 28 Oct 2023   Prob (F-statistic):               0.00\n",
       "Time:                        19:41:47   Log-Likelihood:                 12374.\n",
       "No. Observations:                 422   AIC:                        -2.472e+04\n",
       "Df Residuals:                     406   BIC:                        -2.465e+04\n",
       "Df Model:                          15                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=======================================================================================\n",
       "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------------\n",
       "const                  32.0000   3.98e-14   8.05e+14      0.000      32.000      32.000\n",
       "Explanatory Var #1      1.3000   3.21e-16   4.05e+15      0.000       1.300       1.300\n",
       "Explanatory Var #2      1.7000   2.34e-16   7.27e+15      0.000       1.700       1.700\n",
       "Explanatory Var #3      6.2000   4.48e-15   1.38e+15      0.000       6.200       6.200\n",
       "Explanatory Var #4      2.1000   2.76e-16    7.6e+15      0.000       2.100       2.100\n",
       "Explanatory Var #5     -0.9000   3.24e-16  -2.78e+15      0.000      -0.900      -0.900\n",
       "Explanatory Var #6   9.253e-16   1.95e-16      4.743      0.000    5.42e-16    1.31e-15\n",
       "Explanatory Var #7  -8.635e-16   1.51e-16     -5.719      0.000   -1.16e-15   -5.67e-16\n",
       "Explanatory Var #8   1.138e-15   2.05e-15      0.555      0.579   -2.89e-15    5.17e-15\n",
       "Explanatory Var #9   2.272e-15   2.62e-16      8.668      0.000    1.76e-15    2.79e-15\n",
       "Explanatory Var #10 -2.119e-15   3.26e-16     -6.502      0.000   -2.76e-15   -1.48e-15\n",
       "Explanatory Var #11 -1.166e-15   3.16e-16     -3.692      0.000   -1.79e-15   -5.45e-16\n",
       "Explanatory Var #12  -3.99e-16   2.36e-16     -1.693      0.091   -8.62e-16    6.44e-17\n",
       "Explanatory Var #13 -2.198e-14   4.51e-15     -4.869      0.000   -3.09e-14   -1.31e-14\n",
       "Explanatory Var #14 -1.263e-15   2.77e-16     -4.555      0.000   -1.81e-15   -7.18e-16\n",
       "Explanatory Var #15 -4.163e-16    3.3e-16     -1.263      0.207   -1.06e-15    2.32e-16\n",
       "==============================================================================\n",
       "Omnibus:                        4.416   Durbin-Watson:                   1.919\n",
       "Prob(Omnibus):                  0.110   Jarque-Bera (JB):                4.297\n",
       "Skew:                           0.246   Prob(JB):                        0.117\n",
       "Kurtosis:                       3.044   Cond. No.                     2.53e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 2.53e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.linalg import toeplitz\n",
    "\n",
    "# Autocorrelation values you've calculated, assuming you have them\n",
    "autocorr_values = [autocorr_lag1, autocorr_lag2, autocorr_lag3]\n",
    "\n",
    "# Define the autocorrelation structure\n",
    "autocorr_structure = np.concatenate([[1.0], autocorr_values, np.zeros(418)])\n",
    "\n",
    "# Define the scaling factor (standard deviation)\n",
    "sigma = std_deviation\n",
    "\n",
    "# Create the covariance matrix\n",
    "cov_matrix = sigma**2 * toeplitz(autocorr_structure)\n",
    "\n",
    "# Use the cov_matrix in your GLS model\n",
    "gls_model = sm.GLS(y, X_updated, cov_matrix).fit()\n",
    "\n",
    "gls_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_gls = gls_model.predict(X_updated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Error for OLS model: 4.730391960182503e-14\n",
      "Mean Error for GLS model: 3.594176036307829e-14\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Calculate mean error for OLS model\n",
    "error_ols = np.abs(y - y_pred_ols)\n",
    "mean_error_ols = np.mean(error_ols)\n",
    "\n",
    "# Calculate mean error for GLS model\n",
    "error_gls = np.abs(y - y_pred_gls)\n",
    "mean_error_gls = np.mean(error_gls)\n",
    "\n",
    "print(\"Mean Error for OLS model:\", mean_error_ols)\n",
    "print(\"Mean Error for GLS model:\", mean_error_gls)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GLS handles the inconstant error term, using the autocorrelation value to build the GLS result in a lower Mean Error, which means a better prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.26972628,  1.68394638,  2.02626245,  2.08756512, -0.91746375,\n",
       "       -0.        ,  0.        , -0.        ,  0.        , -0.        ,\n",
       "        0.01314162,  0.        , -0.        ,  0.        , -0.03617731])"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model as lm\n",
    "\n",
    "# lasso\n",
    "model_lasso = lm.Lasso(alpha=1).fit(X_train, y_train)\n",
    "model_lasso.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create prediction \n",
    "y_pred = model_lasso.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to calculate the mape\n",
    "def calculate_mape(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.432190198291579"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the mape for the lasso model\n",
    "mape = calculate_mape(y_test, y_pred)\n",
    "\n",
    "mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Alpha: 0.0001\n",
      "Minimum MAPE: 0.0004248575911965283\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# create parameter grid\n",
    "param_grid = {'alpha': np.logspace(-4, 2, 100)}\n",
    "\n",
    "# create lasso model\n",
    "lasso = lm.Lasso()\n",
    "\n",
    "# create a GridSearchCV object with MAPE as the scoring metric\n",
    "grid_search = GridSearchCV(estimator=lasso, param_grid=param_grid, \n",
    "                           scoring=make_scorer(calculate_mape, greater_is_better=False), cv=10)   \n",
    "\n",
    "# Fit the GridSearchCV to your data (replace X and y with your data)\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Get the best alpha from the grid search\n",
    "best_alpha = grid_search.best_params_['alpha']\n",
    "best_mape = -grid_search.best_score_\n",
    "\n",
    "print(\"Best Alpha:\", best_alpha)\n",
    "print(\"Minimum MAPE:\", best_mape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insight: the lower the Alpha, the lower the MAPE. A smaller alpha might be optimal if your dataset and problem benefit from a more complex model with many non-zero coefficients, and the model generalizes well to unseen data. However, it's crucial to use techniques like cross-validation to ensure that the model doesn't overfit the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>Actual Demand</th>\n",
       "      <th>Advance Demand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>112</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>107</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>103</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>91</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>85</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>84</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>85</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>79</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>81</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>134</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>86</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>89</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>111</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>114</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>118</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>163</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>193</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>143</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>144</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>202</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>158</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>160</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>144</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Month  Actual Demand  Advance Demand\n",
       "0       1            100              71\n",
       "1       2            112              30\n",
       "2       3            107              75\n",
       "3       4            103              64\n",
       "4       5             91              41\n",
       "5       6             85              51\n",
       "6       7             84              42\n",
       "7       8             85              51\n",
       "8       9             79              57\n",
       "9      10             81              49\n",
       "10     11            134             134\n",
       "11     12             86              52\n",
       "12     13             99              99\n",
       "13     14             89              56\n",
       "14     15            111              81\n",
       "15     16            114              79\n",
       "16     17            118              73\n",
       "17     18            163             163\n",
       "18     19            193             193\n",
       "19     20            143              99\n",
       "20     21            144              91\n",
       "21     22            202             202\n",
       "22     23            158             105\n",
       "23     24            160             101\n",
       "24     25            144              96"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generates a DataFrame with the actual and advance demand quantities from the example in the book.\n",
    "\n",
    "def generate_demand():\n",
    "\n",
    "    demand_df = pd.DataFrame()\n",
    "\n",
    "    # actual demand values\n",
    "    actual = [100, 112, 107, 103, 91,\n",
    "              85, 84, 85, 79, 81,\n",
    "              134, 86, 99, 89, 111,\n",
    "              114, 118, 163, 193, 143,\n",
    "              144, 202, 158, 160, 144]\n",
    "\n",
    "    # advance demand values\n",
    "    advance = [71, 30, 75, 64, 41,\n",
    "               51, 42, 51, 57, 49,\n",
    "               134, 52, 99, 56, 81,\n",
    "               79, 73, 163, 193, 99,\n",
    "               91, 202, 105, 101, 96]\n",
    "\n",
    "    demand_df['Month'] = np.arange(1, 26)\n",
    "    demand_df['Actual Demand'] = actual\n",
    "    demand_df['Advance Demand'] = advance\n",
    "\n",
    "    return demand_df\n",
    "\n",
    "demand_df = generate_demand()\n",
    "\n",
    "demand_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the terms in the model\n",
    "\n",
    "def get_terms(demand_df: pd.DataFrame):\n",
    "\n",
    "    Y = np.array(demand_df['Actual Demand'][1:])\n",
    "\n",
    "    X = np.array([\n",
    "            np.ones_like(Y),\n",
    "            demand_df['Actual Demand'][:-1],\n",
    "            demand_df['Advance Demand'][1:]\n",
    "        ]).T\n",
    "\n",
    "    L = np.array(demand_df['Advance Demand'][1:])\n",
    "\n",
    "    return Y, X, L\n",
    "\n",
    "Y, X, L = get_terms(demand_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([112, 107, 103,  91,  85,  84,  85,  79,  81, 134,  86,  99,  89,\n",
       "        111, 114, 118, 163, 193, 143, 144, 202, 158, 160, 144], dtype=int64),\n",
       " array([[  1, 100,  30],\n",
       "        [  1, 112,  75],\n",
       "        [  1, 107,  64],\n",
       "        [  1, 103,  41],\n",
       "        [  1,  91,  51],\n",
       "        [  1,  85,  42],\n",
       "        [  1,  84,  51],\n",
       "        [  1,  85,  57],\n",
       "        [  1,  79,  49],\n",
       "        [  1,  81, 134],\n",
       "        [  1, 134,  52],\n",
       "        [  1,  86,  99],\n",
       "        [  1,  99,  56],\n",
       "        [  1,  89,  81],\n",
       "        [  1, 111,  79],\n",
       "        [  1, 114,  73],\n",
       "        [  1, 118, 163],\n",
       "        [  1, 163, 193],\n",
       "        [  1, 193,  99],\n",
       "        [  1, 143,  91],\n",
       "        [  1, 144, 202],\n",
       "        [  1, 202, 105],\n",
       "        [  1, 158, 101],\n",
       "        [  1, 160,  96]], dtype=int64),\n",
       " array([ 30,  75,  64,  41,  51,  42,  51,  57,  49, 134,  52,  99,  56,\n",
       "         81,  79,  73, 163, 193,  99,  91, 202, 105, 101,  96], dtype=int64))"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y, X, L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build ols model\n",
    "\n",
    "def ols_model(Y, X):\n",
    "\n",
    "    # calculat coefficients for ols model\n",
    "    beta = solve(X.T @ X, np.eye(3)) @ X.T @ Y\n",
    "\n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build regularized model\n",
    "\n",
    "def reg_model(Y, X, L):\n",
    "\n",
    "    lam = np.dot(2*(np.linalg.pinv(np.dot(np.dot(X,np.linalg.pinv(np.dot(X.T,X))),X.T))), L) - 2* Y\n",
    "    lam[lam < 0] = 0\n",
    "    beta_reg = np.dot(np.linalg.pinv(np.dot(X.T, X)), np.dot(X.T, Y) + 0.5*np.dot(lam, X))\n",
    "\n",
    "    return beta_reg, lam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare ols model with the regularized model\n",
    "\n",
    "def compare_models():\n",
    "\n",
    "    # generate demand quantities from example\n",
    "    demand_df = generate_demand()\n",
    "\n",
    "    # get the terms defined in the example\n",
    "    Y, X, L = get_terms(demand_df)\n",
    "\n",
    "    # calculate coefficients of the two models\n",
    "    beta = ols_model(Y, X)\n",
    "    beta_reg, lam = reg_model(Y, X, L)\n",
    "\n",
    "    # calculate the predictions\n",
    "    pred = np.dot(X, beta)\n",
    "    pred_reg = np.dot(X, beta_reg)\n",
    "    pred_reg[np.argwhere(lam > 0)] = L[np.argwhere(lam > 0)]\n",
    "\n",
    "    # calculate the accuracy (MAPE)\n",
    "    mape = calculate_mape(Y, pred)\n",
    "    mape_reg = calculate_mape(Y, pred_reg)\n",
    "\n",
    "    # add result to dataframe and round for plotting\n",
    "    result_df = pd.DataFrame()\n",
    "    result_df = result_df.append({'Model': 'OLS',\n",
    "                                  'mape': round(mape, 4)},\n",
    "                                 ignore_index=True)\n",
    "    result_df = result_df.append({'Model': 'Regularized',\n",
    "                                  'mape': round(mape_reg, 4)},\n",
    "                                 ignore_index=True)\n",
    "\n",
    "    return demand_df, result_df, lam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(    Month  Actual Demand  Advance Demand\n",
       " 0       1            100              71\n",
       " 1       2            112              30\n",
       " 2       3            107              75\n",
       " 3       4            103              64\n",
       " 4       5             91              41\n",
       " 5       6             85              51\n",
       " 6       7             84              42\n",
       " 7       8             85              51\n",
       " 8       9             79              57\n",
       " 9      10             81              49\n",
       " 10     11            134             134\n",
       " 11     12             86              52\n",
       " 12     13             99              99\n",
       " 13     14             89              56\n",
       " 14     15            111              81\n",
       " 15     16            114              79\n",
       " 16     17            118              73\n",
       " 17     18            163             163\n",
       " 18     19            193             193\n",
       " 19     20            143              99\n",
       " 20     21            144              91\n",
       " 21     22            202             202\n",
       " 22     23            158             105\n",
       " 23     24            160             101\n",
       " 24     25            144              96,\n",
       "          Model    mape\n",
       " 0          OLS  6.6713\n",
       " 1  Regularized  6.4382,\n",
       " array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 9.89075488e-12, 0.00000000e+00, 0.00000000e+00,\n",
       "        6.13908924e-12, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00]))"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result shows that regularized model is performing better than normal ols model. Cos when lamda > 0, the model should choose the advance demand.</br>\n",
    "          Model    mape</br>\n",
    " 0          OLS  6.6713<br>\n",
    " 1  Regularized  6.4382</br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
