{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sl\n",
    "import scipy as sp\n",
    "import seaborn as sb\n",
    "from matplotlib import pyplot as plt\n",
    "import oct2py as oclib\n",
    "import numpy as np\n",
    "import matplotlib as mp\n",
    "import statsmodels.api as sm\n",
    "from scipy.linalg import solve, eig\n",
    "import plotly.graph_objects as go\n",
    "from dash import dash_table\n",
    "from statsmodels.sandbox.regression.gmm import IV2SLS \n",
    "# There is a package named IV2SLS in Python. Do not use this package! The exogenous explanatory variables must\n",
    "# be entered as instruments. So it gives wrong answers\n",
    "from statsmodels.sandbox.regression.gmm import GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\oscar\\Downloads\\dataset_lm.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dependent Var</th>\n",
       "      <th>Explanatory Var #1</th>\n",
       "      <th>Explanatory Var #2</th>\n",
       "      <th>Explanatory Var #3</th>\n",
       "      <th>Explanatory Var #4</th>\n",
       "      <th>Explanatory Var #5</th>\n",
       "      <th>Explanatory Var #6</th>\n",
       "      <th>Explanatory Var #7</th>\n",
       "      <th>Explanatory Var #8</th>\n",
       "      <th>Explanatory Var #9</th>\n",
       "      <th>Explanatory Var #10</th>\n",
       "      <th>Explanatory Var #11</th>\n",
       "      <th>Explanatory Var #12</th>\n",
       "      <th>Explanatory Var #13</th>\n",
       "      <th>Explanatory Var #14</th>\n",
       "      <th>Explanatory Var #15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>422.000000</td>\n",
       "      <td>422.000000</td>\n",
       "      <td>422.000000</td>\n",
       "      <td>422.000000</td>\n",
       "      <td>422.000000</td>\n",
       "      <td>422.000000</td>\n",
       "      <td>422.000000</td>\n",
       "      <td>422.000000</td>\n",
       "      <td>422.000000</td>\n",
       "      <td>422.000000</td>\n",
       "      <td>422.000000</td>\n",
       "      <td>422.000000</td>\n",
       "      <td>422.000000</td>\n",
       "      <td>422.000000</td>\n",
       "      <td>422.000000</td>\n",
       "      <td>422.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>67.838396</td>\n",
       "      <td>7.762058</td>\n",
       "      <td>59.725134</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-16.078411</td>\n",
       "      <td>50.133715</td>\n",
       "      <td>10.420808</td>\n",
       "      <td>61.887309</td>\n",
       "      <td>1.566351</td>\n",
       "      <td>-24.511691</td>\n",
       "      <td>49.728665</td>\n",
       "      <td>7.740874</td>\n",
       "      <td>60.765794</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-16.673762</td>\n",
       "      <td>50.066901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>25.676960</td>\n",
       "      <td>7.013243</td>\n",
       "      <td>9.579112</td>\n",
       "      <td>0.500593</td>\n",
       "      <td>8.111197</td>\n",
       "      <td>6.975674</td>\n",
       "      <td>11.520725</td>\n",
       "      <td>14.819969</td>\n",
       "      <td>1.115260</td>\n",
       "      <td>8.500500</td>\n",
       "      <td>6.910690</td>\n",
       "      <td>7.102714</td>\n",
       "      <td>9.525835</td>\n",
       "      <td>0.500593</td>\n",
       "      <td>8.106466</td>\n",
       "      <td>6.794584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.997183</td>\n",
       "      <td>-4.832834</td>\n",
       "      <td>44.124858</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-29.774797</td>\n",
       "      <td>30.009511</td>\n",
       "      <td>-9.828552</td>\n",
       "      <td>34.093154</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-39.979696</td>\n",
       "      <td>26.436407</td>\n",
       "      <td>-4.949728</td>\n",
       "      <td>44.158200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-29.750628</td>\n",
       "      <td>32.118882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>49.482037</td>\n",
       "      <td>1.720182</td>\n",
       "      <td>51.617692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-23.792637</td>\n",
       "      <td>45.423422</td>\n",
       "      <td>-0.174835</td>\n",
       "      <td>49.952772</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-32.037707</td>\n",
       "      <td>45.283603</td>\n",
       "      <td>1.838210</td>\n",
       "      <td>52.849792</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-23.797763</td>\n",
       "      <td>45.825931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>66.780110</td>\n",
       "      <td>7.905455</td>\n",
       "      <td>59.735139</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-15.875481</td>\n",
       "      <td>50.093602</td>\n",
       "      <td>10.422513</td>\n",
       "      <td>62.554591</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-23.767548</td>\n",
       "      <td>49.842746</td>\n",
       "      <td>8.055297</td>\n",
       "      <td>60.773906</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-17.373619</td>\n",
       "      <td>50.038667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>86.801496</td>\n",
       "      <td>13.684104</td>\n",
       "      <td>67.870073</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-9.185191</td>\n",
       "      <td>54.896583</td>\n",
       "      <td>21.059713</td>\n",
       "      <td>74.441216</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>-17.419390</td>\n",
       "      <td>54.576381</td>\n",
       "      <td>14.020396</td>\n",
       "      <td>69.262757</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-9.627544</td>\n",
       "      <td>54.962602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>133.384795</td>\n",
       "      <td>19.973331</td>\n",
       "      <td>76.973576</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-2.060708</td>\n",
       "      <td>70.365951</td>\n",
       "      <td>29.994610</td>\n",
       "      <td>86.895006</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>-10.129522</td>\n",
       "      <td>68.201681</td>\n",
       "      <td>19.992891</td>\n",
       "      <td>76.639179</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-2.003168</td>\n",
       "      <td>69.147818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Dependent Var  Explanatory Var #1  Explanatory Var #2  \\\n",
       "count     422.000000          422.000000          422.000000   \n",
       "mean       67.838396            7.762058           59.725134   \n",
       "std        25.676960            7.013243            9.579112   \n",
       "min        -2.997183           -4.832834           44.124858   \n",
       "25%        49.482037            1.720182           51.617692   \n",
       "50%        66.780110            7.905455           59.735139   \n",
       "75%        86.801496           13.684104           67.870073   \n",
       "max       133.384795           19.973331           76.973576   \n",
       "\n",
       "       Explanatory Var #3  Explanatory Var #4  Explanatory Var #5  \\\n",
       "count          422.000000          422.000000          422.000000   \n",
       "mean             0.500000          -16.078411           50.133715   \n",
       "std              0.500593            8.111197            6.975674   \n",
       "min              0.000000          -29.774797           30.009511   \n",
       "25%              0.000000          -23.792637           45.423422   \n",
       "50%              0.500000          -15.875481           50.093602   \n",
       "75%              1.000000           -9.185191           54.896583   \n",
       "max              1.000000           -2.060708           70.365951   \n",
       "\n",
       "       Explanatory Var #6  Explanatory Var #7  Explanatory Var #8  \\\n",
       "count          422.000000          422.000000          422.000000   \n",
       "mean            10.420808           61.887309            1.566351   \n",
       "std             11.520725           14.819969            1.115260   \n",
       "min             -9.828552           34.093154            0.000000   \n",
       "25%             -0.174835           49.952772            1.000000   \n",
       "50%             10.422513           62.554591            2.000000   \n",
       "75%             21.059713           74.441216            3.000000   \n",
       "max             29.994610           86.895006            3.000000   \n",
       "\n",
       "       Explanatory Var #9  Explanatory Var #10  Explanatory Var #11  \\\n",
       "count          422.000000           422.000000           422.000000   \n",
       "mean           -24.511691            49.728665             7.740874   \n",
       "std              8.500500             6.910690             7.102714   \n",
       "min            -39.979696            26.436407            -4.949728   \n",
       "25%            -32.037707            45.283603             1.838210   \n",
       "50%            -23.767548            49.842746             8.055297   \n",
       "75%            -17.419390            54.576381            14.020396   \n",
       "max            -10.129522            68.201681            19.992891   \n",
       "\n",
       "       Explanatory Var #12  Explanatory Var #13  Explanatory Var #14  \\\n",
       "count           422.000000           422.000000           422.000000   \n",
       "mean             60.765794             0.500000           -16.673762   \n",
       "std               9.525835             0.500593             8.106466   \n",
       "min              44.158200             0.000000           -29.750628   \n",
       "25%              52.849792             0.000000           -23.797763   \n",
       "50%              60.773906             0.500000           -17.373619   \n",
       "75%              69.262757             1.000000            -9.627544   \n",
       "max              76.639179             1.000000            -2.003168   \n",
       "\n",
       "       Explanatory Var #15  \n",
       "count           422.000000  \n",
       "mean             50.066901  \n",
       "std               6.794584  \n",
       "min              32.118882  \n",
       "25%              45.825931  \n",
       "50%              50.038667  \n",
       "75%              54.962602  \n",
       "max              69.147818  "
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Dependent Var', 'Explanatory Var #1', 'Explanatory Var #2',\n",
       "       'Explanatory Var #3', 'Explanatory Var #4', 'Explanatory Var #5',\n",
       "       'Explanatory Var #6', 'Explanatory Var #7', 'Explanatory Var #8',\n",
       "       'Explanatory Var #9', 'Explanatory Var #10', 'Explanatory Var #11',\n",
       "       'Explanatory Var #12', 'Explanatory Var #13', 'Explanatory Var #14',\n",
       "       'Explanatory Var #15'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"Dependent Var\"])\n",
    "y = df[\"Dependent Var\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>      <td>Dependent Var</td>  <th>  R-squared (uncentered):</th>      <td>   0.999</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.999</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>4.509e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 28 Oct 2023</td> <th>  Prob (F-statistic):</th>           <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>18:57:28</td>     <th>  Log-Likelihood:    </th>          <td> -841.76</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   422</td>      <th>  AIC:               </th>          <td>   1714.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   407</td>      <th>  BIC:               </th>          <td>   1774.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    15</td>      <th>                     </th>              <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>              <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #1</th>  <td>    1.3078</td> <td>    0.013</td> <td>  102.159</td> <td> 0.000</td> <td>    1.283</td> <td>    1.333</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #2</th>  <td>    1.7667</td> <td>    0.009</td> <td>  203.101</td> <td> 0.000</td> <td>    1.750</td> <td>    1.784</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #3</th>  <td>    6.6083</td> <td>    0.177</td> <td>   37.232</td> <td> 0.000</td> <td>    6.259</td> <td>    6.957</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #4</th>  <td>    2.0725</td> <td>    0.011</td> <td>  189.896</td> <td> 0.000</td> <td>    2.051</td> <td>    2.094</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #5</th>  <td>   -0.7776</td> <td>    0.011</td> <td>  -68.372</td> <td> 0.000</td> <td>   -0.800</td> <td>   -0.755</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #6</th>  <td>    0.0124</td> <td>    0.008</td> <td>    1.595</td> <td> 0.111</td> <td>   -0.003</td> <td>    0.028</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #7</th>  <td>    0.0286</td> <td>    0.006</td> <td>    4.890</td> <td> 0.000</td> <td>    0.017</td> <td>    0.040</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #8</th>  <td>    0.3510</td> <td>    0.080</td> <td>    4.398</td> <td> 0.000</td> <td>    0.194</td> <td>    0.508</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #9</th>  <td>   -0.0293</td> <td>    0.010</td> <td>   -2.838</td> <td> 0.005</td> <td>   -0.050</td> <td>   -0.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #10</th> <td>    0.1292</td> <td>    0.011</td> <td>   11.409</td> <td> 0.000</td> <td>    0.107</td> <td>    0.152</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #11</th> <td>    0.0145</td> <td>    0.013</td> <td>    1.152</td> <td> 0.250</td> <td>   -0.010</td> <td>    0.039</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #12</th> <td>    0.0752</td> <td>    0.009</td> <td>    8.698</td> <td> 0.000</td> <td>    0.058</td> <td>    0.092</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #13</th> <td>    0.7414</td> <td>    0.177</td> <td>    4.198</td> <td> 0.000</td> <td>    0.394</td> <td>    1.089</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #14</th> <td>   -0.0218</td> <td>    0.011</td> <td>   -1.974</td> <td> 0.049</td> <td>   -0.043</td> <td>-8.61e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #15</th> <td>    0.1212</td> <td>    0.012</td> <td>   10.324</td> <td> 0.000</td> <td>    0.098</td> <td>    0.144</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.087</td> <th>  Durbin-Watson:     </th> <td>   1.875</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.957</td> <th>  Jarque-Bera (JB):  </th> <td>   0.188</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.004</td> <th>  Prob(JB):          </th> <td>   0.910</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.897</td> <th>  Cond. No.          </th> <td>    287.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] R² is computed without centering (uncentered) since the model does not contain a constant.<br/>[2] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}       &  Dependent Var   & \\textbf{  R-squared (uncentered):}      &     0.999   \\\\\n",
       "\\textbf{Model:}               &       OLS        & \\textbf{  Adj. R-squared (uncentered):} &     0.999   \\\\\n",
       "\\textbf{Method:}              &  Least Squares   & \\textbf{  F-statistic:       }          & 4.509e+04   \\\\\n",
       "\\textbf{Date:}                & Sat, 28 Oct 2023 & \\textbf{  Prob (F-statistic):}          &     0.00    \\\\\n",
       "\\textbf{Time:}                &     18:57:28     & \\textbf{  Log-Likelihood:    }          &   -841.76   \\\\\n",
       "\\textbf{No. Observations:}    &         422      & \\textbf{  AIC:               }          &     1714.   \\\\\n",
       "\\textbf{Df Residuals:}        &         407      & \\textbf{  BIC:               }          &     1774.   \\\\\n",
       "\\textbf{Df Model:}            &          15      & \\textbf{                     }          &             \\\\\n",
       "\\textbf{Covariance Type:}     &    nonrobust     & \\textbf{                     }          &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                              & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Explanatory Var \\#1}  &       1.3078  &        0.013     &   102.159  &         0.000        &        1.283    &        1.333     \\\\\n",
       "\\textbf{Explanatory Var \\#2}  &       1.7667  &        0.009     &   203.101  &         0.000        &        1.750    &        1.784     \\\\\n",
       "\\textbf{Explanatory Var \\#3}  &       6.6083  &        0.177     &    37.232  &         0.000        &        6.259    &        6.957     \\\\\n",
       "\\textbf{Explanatory Var \\#4}  &       2.0725  &        0.011     &   189.896  &         0.000        &        2.051    &        2.094     \\\\\n",
       "\\textbf{Explanatory Var \\#5}  &      -0.7776  &        0.011     &   -68.372  &         0.000        &       -0.800    &       -0.755     \\\\\n",
       "\\textbf{Explanatory Var \\#6}  &       0.0124  &        0.008     &     1.595  &         0.111        &       -0.003    &        0.028     \\\\\n",
       "\\textbf{Explanatory Var \\#7}  &       0.0286  &        0.006     &     4.890  &         0.000        &        0.017    &        0.040     \\\\\n",
       "\\textbf{Explanatory Var \\#8}  &       0.3510  &        0.080     &     4.398  &         0.000        &        0.194    &        0.508     \\\\\n",
       "\\textbf{Explanatory Var \\#9}  &      -0.0293  &        0.010     &    -2.838  &         0.005        &       -0.050    &       -0.009     \\\\\n",
       "\\textbf{Explanatory Var \\#10} &       0.1292  &        0.011     &    11.409  &         0.000        &        0.107    &        0.152     \\\\\n",
       "\\textbf{Explanatory Var \\#11} &       0.0145  &        0.013     &     1.152  &         0.250        &       -0.010    &        0.039     \\\\\n",
       "\\textbf{Explanatory Var \\#12} &       0.0752  &        0.009     &     8.698  &         0.000        &        0.058    &        0.092     \\\\\n",
       "\\textbf{Explanatory Var \\#13} &       0.7414  &        0.177     &     4.198  &         0.000        &        0.394    &        1.089     \\\\\n",
       "\\textbf{Explanatory Var \\#14} &      -0.0218  &        0.011     &    -1.974  &         0.049        &       -0.043    &    -8.61e-05     \\\\\n",
       "\\textbf{Explanatory Var \\#15} &       0.1212  &        0.012     &    10.324  &         0.000        &        0.098    &        0.144     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  0.087 & \\textbf{  Durbin-Watson:     } &    1.875  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.957 & \\textbf{  Jarque-Bera (JB):  } &    0.188  \\\\\n",
       "\\textbf{Skew:}          & -0.004 & \\textbf{  Prob(JB):          } &    0.910  \\\\\n",
       "\\textbf{Kurtosis:}      &  2.897 & \\textbf{  Cond. No.          } &     287.  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] R² is computed without centering (uncentered) since the model does not contain a constant. \\newline\n",
       " [2] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 OLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:          Dependent Var   R-squared (uncentered):                   0.999\n",
       "Model:                            OLS   Adj. R-squared (uncentered):              0.999\n",
       "Method:                 Least Squares   F-statistic:                          4.509e+04\n",
       "Date:                Sat, 28 Oct 2023   Prob (F-statistic):                        0.00\n",
       "Time:                        18:57:28   Log-Likelihood:                         -841.76\n",
       "No. Observations:                 422   AIC:                                      1714.\n",
       "Df Residuals:                     407   BIC:                                      1774.\n",
       "Df Model:                          15                                                  \n",
       "Covariance Type:            nonrobust                                                  \n",
       "=======================================================================================\n",
       "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------------\n",
       "Explanatory Var #1      1.3078      0.013    102.159      0.000       1.283       1.333\n",
       "Explanatory Var #2      1.7667      0.009    203.101      0.000       1.750       1.784\n",
       "Explanatory Var #3      6.6083      0.177     37.232      0.000       6.259       6.957\n",
       "Explanatory Var #4      2.0725      0.011    189.896      0.000       2.051       2.094\n",
       "Explanatory Var #5     -0.7776      0.011    -68.372      0.000      -0.800      -0.755\n",
       "Explanatory Var #6      0.0124      0.008      1.595      0.111      -0.003       0.028\n",
       "Explanatory Var #7      0.0286      0.006      4.890      0.000       0.017       0.040\n",
       "Explanatory Var #8      0.3510      0.080      4.398      0.000       0.194       0.508\n",
       "Explanatory Var #9     -0.0293      0.010     -2.838      0.005      -0.050      -0.009\n",
       "Explanatory Var #10     0.1292      0.011     11.409      0.000       0.107       0.152\n",
       "Explanatory Var #11     0.0145      0.013      1.152      0.250      -0.010       0.039\n",
       "Explanatory Var #12     0.0752      0.009      8.698      0.000       0.058       0.092\n",
       "Explanatory Var #13     0.7414      0.177      4.198      0.000       0.394       1.089\n",
       "Explanatory Var #14    -0.0218      0.011     -1.974      0.049      -0.043   -8.61e-05\n",
       "Explanatory Var #15     0.1212      0.012     10.324      0.000       0.098       0.144\n",
       "==============================================================================\n",
       "Omnibus:                        0.087   Durbin-Watson:                   1.875\n",
       "Prob(Omnibus):                  0.957   Jarque-Bera (JB):                0.188\n",
       "Skew:                          -0.004   Prob(JB):                        0.910\n",
       "Kurtosis:                       2.897   Cond. No.                         287.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
       "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ols = sm.OLS(y, X).fit()\n",
    "model_ols.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No intercept, so add constant is needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>      <td>Dependent Var</td>  <th>  R-squared:         </th>  <td>   1.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   1.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>5.506e+30</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 28 Oct 2023</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>18:57:28</td>     <th>  Log-Likelihood:    </th>  <td>  12271.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   422</td>      <th>  AIC:               </th> <td>-2.451e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   406</td>      <th>  BIC:               </th> <td>-2.445e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    15</td>      <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>              <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>               <td>   32.0000</td> <td> 5.08e-14</td> <td>  6.3e+14</td> <td> 0.000</td> <td>   32.000</td> <td>   32.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #1</th>  <td>    1.3000</td> <td>  4.1e-16</td> <td> 3.17e+15</td> <td> 0.000</td> <td>    1.300</td> <td>    1.300</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #2</th>  <td>    1.7000</td> <td> 2.98e-16</td> <td> 5.71e+15</td> <td> 0.000</td> <td>    1.700</td> <td>    1.700</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #3</th>  <td>    6.2000</td> <td> 5.72e-15</td> <td> 1.08e+15</td> <td> 0.000</td> <td>    6.200</td> <td>    6.200</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #4</th>  <td>    2.1000</td> <td> 3.52e-16</td> <td> 5.96e+15</td> <td> 0.000</td> <td>    2.100</td> <td>    2.100</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #5</th>  <td>   -0.9000</td> <td> 4.13e-16</td> <td>-2.18e+15</td> <td> 0.000</td> <td>   -0.900</td> <td>   -0.900</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #6</th>  <td> -9.86e-16</td> <td> 2.49e-16</td> <td>   -3.959</td> <td> 0.000</td> <td>-1.48e-15</td> <td>-4.96e-16</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #7</th>  <td>-7.268e-16</td> <td> 1.92e-16</td> <td>   -3.778</td> <td> 0.000</td> <td>-1.11e-15</td> <td>-3.49e-16</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #8</th>  <td>-8.604e-16</td> <td> 2.61e-15</td> <td>   -0.329</td> <td> 0.742</td> <td>   -6e-15</td> <td> 4.28e-15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #9</th>  <td>  1.11e-15</td> <td> 3.34e-16</td> <td>    3.322</td> <td> 0.001</td> <td> 4.53e-16</td> <td> 1.77e-15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #10</th> <td>-5.438e-16</td> <td> 4.17e-16</td> <td>   -1.305</td> <td> 0.193</td> <td>-1.36e-15</td> <td> 2.75e-16</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #11</th> <td> 7.494e-16</td> <td> 4.03e-16</td> <td>    1.860</td> <td> 0.064</td> <td>-4.26e-17</td> <td> 1.54e-15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #12</th> <td>-4.111e-16</td> <td> 3.01e-16</td> <td>   -1.364</td> <td> 0.173</td> <td>   -1e-15</td> <td> 1.81e-16</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #13</th> <td>-2.201e-14</td> <td> 5.77e-15</td> <td>   -3.811</td> <td> 0.000</td> <td>-3.34e-14</td> <td>-1.07e-14</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #14</th> <td>  1.69e-15</td> <td> 3.55e-16</td> <td>    4.768</td> <td> 0.000</td> <td> 9.94e-16</td> <td> 2.39e-15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #15</th> <td>-8.916e-16</td> <td> 4.22e-16</td> <td>   -2.112</td> <td> 0.035</td> <td>-1.72e-15</td> <td>-6.17e-17</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.278</td> <th>  Durbin-Watson:     </th> <td>   0.806</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.528</td> <th>  Jarque-Bera (JB):  </th> <td>   1.327</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.131</td> <th>  Prob(JB):          </th> <td>   0.515</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.918</td> <th>  Cond. No.          </th> <td>2.55e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.55e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}       &  Dependent Var   & \\textbf{  R-squared:         } &     1.000   \\\\\n",
       "\\textbf{Model:}               &       OLS        & \\textbf{  Adj. R-squared:    } &     1.000   \\\\\n",
       "\\textbf{Method:}              &  Least Squares   & \\textbf{  F-statistic:       } & 5.506e+30   \\\\\n",
       "\\textbf{Date:}                & Sat, 28 Oct 2023 & \\textbf{  Prob (F-statistic):} &     0.00    \\\\\n",
       "\\textbf{Time:}                &     18:57:28     & \\textbf{  Log-Likelihood:    } &    12271.   \\\\\n",
       "\\textbf{No. Observations:}    &         422      & \\textbf{  AIC:               } & -2.451e+04  \\\\\n",
       "\\textbf{Df Residuals:}        &         406      & \\textbf{  BIC:               } & -2.445e+04  \\\\\n",
       "\\textbf{Df Model:}            &          15      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}     &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                              & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const}                &      32.0000  &     5.08e-14     &   6.3e+14  &         0.000        &       32.000    &       32.000     \\\\\n",
       "\\textbf{Explanatory Var \\#1}  &       1.3000  &      4.1e-16     &  3.17e+15  &         0.000        &        1.300    &        1.300     \\\\\n",
       "\\textbf{Explanatory Var \\#2}  &       1.7000  &     2.98e-16     &  5.71e+15  &         0.000        &        1.700    &        1.700     \\\\\n",
       "\\textbf{Explanatory Var \\#3}  &       6.2000  &     5.72e-15     &  1.08e+15  &         0.000        &        6.200    &        6.200     \\\\\n",
       "\\textbf{Explanatory Var \\#4}  &       2.1000  &     3.52e-16     &  5.96e+15  &         0.000        &        2.100    &        2.100     \\\\\n",
       "\\textbf{Explanatory Var \\#5}  &      -0.9000  &     4.13e-16     & -2.18e+15  &         0.000        &       -0.900    &       -0.900     \\\\\n",
       "\\textbf{Explanatory Var \\#6}  &    -9.86e-16  &     2.49e-16     &    -3.959  &         0.000        &    -1.48e-15    &    -4.96e-16     \\\\\n",
       "\\textbf{Explanatory Var \\#7}  &   -7.268e-16  &     1.92e-16     &    -3.778  &         0.000        &    -1.11e-15    &    -3.49e-16     \\\\\n",
       "\\textbf{Explanatory Var \\#8}  &   -8.604e-16  &     2.61e-15     &    -0.329  &         0.742        &       -6e-15    &     4.28e-15     \\\\\n",
       "\\textbf{Explanatory Var \\#9}  &     1.11e-15  &     3.34e-16     &     3.322  &         0.001        &     4.53e-16    &     1.77e-15     \\\\\n",
       "\\textbf{Explanatory Var \\#10} &   -5.438e-16  &     4.17e-16     &    -1.305  &         0.193        &    -1.36e-15    &     2.75e-16     \\\\\n",
       "\\textbf{Explanatory Var \\#11} &    7.494e-16  &     4.03e-16     &     1.860  &         0.064        &    -4.26e-17    &     1.54e-15     \\\\\n",
       "\\textbf{Explanatory Var \\#12} &   -4.111e-16  &     3.01e-16     &    -1.364  &         0.173        &       -1e-15    &     1.81e-16     \\\\\n",
       "\\textbf{Explanatory Var \\#13} &   -2.201e-14  &     5.77e-15     &    -3.811  &         0.000        &    -3.34e-14    &    -1.07e-14     \\\\\n",
       "\\textbf{Explanatory Var \\#14} &     1.69e-15  &     3.55e-16     &     4.768  &         0.000        &     9.94e-16    &     2.39e-15     \\\\\n",
       "\\textbf{Explanatory Var \\#15} &   -8.916e-16  &     4.22e-16     &    -2.112  &         0.035        &    -1.72e-15    &    -6.17e-17     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  1.278 & \\textbf{  Durbin-Watson:     } &    0.806  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.528 & \\textbf{  Jarque-Bera (JB):  } &    1.327  \\\\\n",
       "\\textbf{Skew:}          & -0.131 & \\textbf{  Prob(JB):          } &    0.515  \\\\\n",
       "\\textbf{Kurtosis:}      &  2.918 & \\textbf{  Cond. No.          } & 2.55e+03  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 2.55e+03. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:          Dependent Var   R-squared:                       1.000\n",
       "Model:                            OLS   Adj. R-squared:                  1.000\n",
       "Method:                 Least Squares   F-statistic:                 5.506e+30\n",
       "Date:                Sat, 28 Oct 2023   Prob (F-statistic):               0.00\n",
       "Time:                        18:57:28   Log-Likelihood:                 12271.\n",
       "No. Observations:                 422   AIC:                        -2.451e+04\n",
       "Df Residuals:                     406   BIC:                        -2.445e+04\n",
       "Df Model:                          15                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=======================================================================================\n",
       "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------------\n",
       "const                  32.0000   5.08e-14    6.3e+14      0.000      32.000      32.000\n",
       "Explanatory Var #1      1.3000    4.1e-16   3.17e+15      0.000       1.300       1.300\n",
       "Explanatory Var #2      1.7000   2.98e-16   5.71e+15      0.000       1.700       1.700\n",
       "Explanatory Var #3      6.2000   5.72e-15   1.08e+15      0.000       6.200       6.200\n",
       "Explanatory Var #4      2.1000   3.52e-16   5.96e+15      0.000       2.100       2.100\n",
       "Explanatory Var #5     -0.9000   4.13e-16  -2.18e+15      0.000      -0.900      -0.900\n",
       "Explanatory Var #6   -9.86e-16   2.49e-16     -3.959      0.000   -1.48e-15   -4.96e-16\n",
       "Explanatory Var #7  -7.268e-16   1.92e-16     -3.778      0.000   -1.11e-15   -3.49e-16\n",
       "Explanatory Var #8  -8.604e-16   2.61e-15     -0.329      0.742      -6e-15    4.28e-15\n",
       "Explanatory Var #9    1.11e-15   3.34e-16      3.322      0.001    4.53e-16    1.77e-15\n",
       "Explanatory Var #10 -5.438e-16   4.17e-16     -1.305      0.193   -1.36e-15    2.75e-16\n",
       "Explanatory Var #11  7.494e-16   4.03e-16      1.860      0.064   -4.26e-17    1.54e-15\n",
       "Explanatory Var #12 -4.111e-16   3.01e-16     -1.364      0.173      -1e-15    1.81e-16\n",
       "Explanatory Var #13 -2.201e-14   5.77e-15     -3.811      0.000   -3.34e-14   -1.07e-14\n",
       "Explanatory Var #14   1.69e-15   3.55e-16      4.768      0.000    9.94e-16    2.39e-15\n",
       "Explanatory Var #15 -8.916e-16   4.22e-16     -2.112      0.035   -1.72e-15   -6.17e-17\n",
       "==============================================================================\n",
       "Omnibus:                        1.278   Durbin-Watson:                   0.806\n",
       "Prob(Omnibus):                  0.528   Jarque-Bera (JB):                1.327\n",
       "Skew:                          -0.131   Prob(JB):                        0.515\n",
       "Kurtosis:                       2.918   Cond. No.                     2.55e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 2.55e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_updated = sm.add_constant(X)\n",
    "model_updated = sm.OLS(y,X_updated).fit()\n",
    "model_updated.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the residual of the ols model\n",
    "residuals = model_updated.resid\n",
    "\n",
    "# Calculate the standard deviation of the residuals\n",
    "std_deviation = np.std(residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     -5.684342e-14\n",
       "1     -5.684342e-14\n",
       "2      1.421085e-14\n",
       "3     -1.207923e-13\n",
       "4     -2.842171e-14\n",
       "           ...     \n",
       "417   -5.684342e-14\n",
       "418   -3.552714e-14\n",
       "419   -4.263256e-14\n",
       "420    7.105427e-15\n",
       "421   -7.815970e-14\n",
       "Length: 422, dtype: float64"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Deviation of Residuals: 3.658463587473027e-14\n",
      "Autocorrelation at Lag 1: 0.025640755881955277\n",
      "Autocorrelation at Lag 2: -0.025076901695316168\n",
      "Autocorrelation at Lag 3: 0.004619065512860453\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.stattools import acf\n",
    "\n",
    "# Calculate the autocorrelation for the first three lags\n",
    "lags = 3\n",
    "a_values = acf(residuals, nlags=lags)\n",
    "\n",
    "# Extract autocorrelation values for each lag\n",
    "autocorr_lag1 = a_values[1]  # Autocorrelation at lag 1\n",
    "autocorr_lag2 = a_values[2]  # Autocorrelation at lag 2\n",
    "autocorr_lag3 = a_values[3]  # Autocorrelation at lag 3\n",
    "\n",
    "print(\"Standard Deviation of Residuals:\", std_deviation)\n",
    "print(\"Autocorrelation at Lag 1:\", autocorr_lag1)\n",
    "print(\"Autocorrelation at Lag 2:\", autocorr_lag2)\n",
    "print(\"Autocorrelation at Lag 3:\", autocorr_lag3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import acf\n",
    "\n",
    "lags = 3\n",
    "a_values = acf(residuals, nlags=lags)\n",
    "\n",
    "# Extract autocorrelation values for each lag\n",
    "autocorr_lag1 = a_values[1]\n",
    "autocorr_lag2 = a_values[2] \n",
    "autocorr_lag3 = a_values[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>GLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>      <td>Dependent Var</td>  <th>  R-squared:         </th>  <td>   1.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>GLS</td>       <th>  Adj. R-squared:    </th>  <td>   1.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>4.156e+30</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 28 Oct 2023</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>18:57:28</td>     <th>  Log-Likelihood:    </th>  <td>  12213.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   422</td>      <th>  AIC:               </th> <td>-2.439e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   406</td>      <th>  BIC:               </th> <td>-2.433e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    15</td>      <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>              <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>               <td>   32.0000</td> <td> 5.83e-14</td> <td> 5.49e+14</td> <td> 0.000</td> <td>   32.000</td> <td>   32.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #1</th>  <td>    1.3000</td> <td> 4.71e-16</td> <td> 2.76e+15</td> <td> 0.000</td> <td>    1.300</td> <td>    1.300</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #2</th>  <td>    1.7000</td> <td> 3.43e-16</td> <td> 4.96e+15</td> <td> 0.000</td> <td>    1.700</td> <td>    1.700</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #3</th>  <td>    6.2000</td> <td> 6.57e-15</td> <td> 9.44e+14</td> <td> 0.000</td> <td>    6.200</td> <td>    6.200</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #4</th>  <td>    2.1000</td> <td> 4.05e-16</td> <td> 5.19e+15</td> <td> 0.000</td> <td>    2.100</td> <td>    2.100</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #5</th>  <td>   -0.9000</td> <td> 4.75e-16</td> <td> -1.9e+15</td> <td> 0.000</td> <td>   -0.900</td> <td>   -0.900</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #6</th>  <td> 9.541e-16</td> <td> 2.86e-16</td> <td>    3.337</td> <td> 0.001</td> <td> 3.92e-16</td> <td> 1.52e-15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #7</th>  <td>-1.164e-15</td> <td> 2.21e-16</td> <td>   -5.258</td> <td> 0.000</td> <td> -1.6e-15</td> <td>-7.29e-16</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #8</th>  <td> 2.026e-15</td> <td>    3e-15</td> <td>    0.675</td> <td> 0.500</td> <td>-3.88e-15</td> <td> 7.93e-15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #9</th>  <td> 1.638e-15</td> <td> 3.84e-16</td> <td>    4.261</td> <td> 0.000</td> <td> 8.82e-16</td> <td> 2.39e-15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #10</th> <td>-2.508e-15</td> <td> 4.78e-16</td> <td>   -5.251</td> <td> 0.000</td> <td>-3.45e-15</td> <td>-1.57e-15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #11</th> <td> 7.147e-16</td> <td> 4.63e-16</td> <td>    1.544</td> <td> 0.123</td> <td>-1.95e-16</td> <td> 1.62e-15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #12</th> <td>-1.641e-15</td> <td> 3.46e-16</td> <td>   -4.749</td> <td> 0.000</td> <td>-2.32e-15</td> <td>-9.62e-16</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #13</th> <td>-1.865e-14</td> <td> 6.62e-15</td> <td>   -2.818</td> <td> 0.005</td> <td>-3.17e-14</td> <td>-5.64e-15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #14</th> <td> 3.592e-15</td> <td> 4.06e-16</td> <td>    8.837</td> <td> 0.000</td> <td> 2.79e-15</td> <td> 4.39e-15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Explanatory Var #15</th> <td>-2.078e-15</td> <td> 4.83e-16</td> <td>   -4.300</td> <td> 0.000</td> <td>-3.03e-15</td> <td>-1.13e-15</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.684</td> <th>  Durbin-Watson:     </th> <td>   1.797</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.431</td> <th>  Jarque-Bera (JB):  </th> <td>   1.518</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.007</td> <th>  Prob(JB):          </th> <td>   0.468</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.707</td> <th>  Cond. No.          </th> <td>2.53e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.53e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}       &  Dependent Var   & \\textbf{  R-squared:         } &     1.000   \\\\\n",
       "\\textbf{Model:}               &       GLS        & \\textbf{  Adj. R-squared:    } &     1.000   \\\\\n",
       "\\textbf{Method:}              &  Least Squares   & \\textbf{  F-statistic:       } & 4.156e+30   \\\\\n",
       "\\textbf{Date:}                & Sat, 28 Oct 2023 & \\textbf{  Prob (F-statistic):} &     0.00    \\\\\n",
       "\\textbf{Time:}                &     18:57:28     & \\textbf{  Log-Likelihood:    } &    12213.   \\\\\n",
       "\\textbf{No. Observations:}    &         422      & \\textbf{  AIC:               } & -2.439e+04  \\\\\n",
       "\\textbf{Df Residuals:}        &         406      & \\textbf{  BIC:               } & -2.433e+04  \\\\\n",
       "\\textbf{Df Model:}            &          15      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}     &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                              & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const}                &      32.0000  &     5.83e-14     &  5.49e+14  &         0.000        &       32.000    &       32.000     \\\\\n",
       "\\textbf{Explanatory Var \\#1}  &       1.3000  &     4.71e-16     &  2.76e+15  &         0.000        &        1.300    &        1.300     \\\\\n",
       "\\textbf{Explanatory Var \\#2}  &       1.7000  &     3.43e-16     &  4.96e+15  &         0.000        &        1.700    &        1.700     \\\\\n",
       "\\textbf{Explanatory Var \\#3}  &       6.2000  &     6.57e-15     &  9.44e+14  &         0.000        &        6.200    &        6.200     \\\\\n",
       "\\textbf{Explanatory Var \\#4}  &       2.1000  &     4.05e-16     &  5.19e+15  &         0.000        &        2.100    &        2.100     \\\\\n",
       "\\textbf{Explanatory Var \\#5}  &      -0.9000  &     4.75e-16     &  -1.9e+15  &         0.000        &       -0.900    &       -0.900     \\\\\n",
       "\\textbf{Explanatory Var \\#6}  &    9.541e-16  &     2.86e-16     &     3.337  &         0.001        &     3.92e-16    &     1.52e-15     \\\\\n",
       "\\textbf{Explanatory Var \\#7}  &   -1.164e-15  &     2.21e-16     &    -5.258  &         0.000        &     -1.6e-15    &    -7.29e-16     \\\\\n",
       "\\textbf{Explanatory Var \\#8}  &    2.026e-15  &        3e-15     &     0.675  &         0.500        &    -3.88e-15    &     7.93e-15     \\\\\n",
       "\\textbf{Explanatory Var \\#9}  &    1.638e-15  &     3.84e-16     &     4.261  &         0.000        &     8.82e-16    &     2.39e-15     \\\\\n",
       "\\textbf{Explanatory Var \\#10} &   -2.508e-15  &     4.78e-16     &    -5.251  &         0.000        &    -3.45e-15    &    -1.57e-15     \\\\\n",
       "\\textbf{Explanatory Var \\#11} &    7.147e-16  &     4.63e-16     &     1.544  &         0.123        &    -1.95e-16    &     1.62e-15     \\\\\n",
       "\\textbf{Explanatory Var \\#12} &   -1.641e-15  &     3.46e-16     &    -4.749  &         0.000        &    -2.32e-15    &    -9.62e-16     \\\\\n",
       "\\textbf{Explanatory Var \\#13} &   -1.865e-14  &     6.62e-15     &    -2.818  &         0.005        &    -3.17e-14    &    -5.64e-15     \\\\\n",
       "\\textbf{Explanatory Var \\#14} &    3.592e-15  &     4.06e-16     &     8.837  &         0.000        &     2.79e-15    &     4.39e-15     \\\\\n",
       "\\textbf{Explanatory Var \\#15} &   -2.078e-15  &     4.83e-16     &    -4.300  &         0.000        &    -3.03e-15    &    -1.13e-15     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  1.684 & \\textbf{  Durbin-Watson:     } &    1.797  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.431 & \\textbf{  Jarque-Bera (JB):  } &    1.518  \\\\\n",
       "\\textbf{Skew:}          & -0.007 & \\textbf{  Prob(JB):          } &    0.468  \\\\\n",
       "\\textbf{Kurtosis:}      &  2.707 & \\textbf{  Cond. No.          } & 2.53e+03  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{GLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 2.53e+03. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            GLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:          Dependent Var   R-squared:                       1.000\n",
       "Model:                            GLS   Adj. R-squared:                  1.000\n",
       "Method:                 Least Squares   F-statistic:                 4.156e+30\n",
       "Date:                Sat, 28 Oct 2023   Prob (F-statistic):               0.00\n",
       "Time:                        18:57:28   Log-Likelihood:                 12213.\n",
       "No. Observations:                 422   AIC:                        -2.439e+04\n",
       "Df Residuals:                     406   BIC:                        -2.433e+04\n",
       "Df Model:                          15                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=======================================================================================\n",
       "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------------\n",
       "const                  32.0000   5.83e-14   5.49e+14      0.000      32.000      32.000\n",
       "Explanatory Var #1      1.3000   4.71e-16   2.76e+15      0.000       1.300       1.300\n",
       "Explanatory Var #2      1.7000   3.43e-16   4.96e+15      0.000       1.700       1.700\n",
       "Explanatory Var #3      6.2000   6.57e-15   9.44e+14      0.000       6.200       6.200\n",
       "Explanatory Var #4      2.1000   4.05e-16   5.19e+15      0.000       2.100       2.100\n",
       "Explanatory Var #5     -0.9000   4.75e-16   -1.9e+15      0.000      -0.900      -0.900\n",
       "Explanatory Var #6   9.541e-16   2.86e-16      3.337      0.001    3.92e-16    1.52e-15\n",
       "Explanatory Var #7  -1.164e-15   2.21e-16     -5.258      0.000    -1.6e-15   -7.29e-16\n",
       "Explanatory Var #8   2.026e-15      3e-15      0.675      0.500   -3.88e-15    7.93e-15\n",
       "Explanatory Var #9   1.638e-15   3.84e-16      4.261      0.000    8.82e-16    2.39e-15\n",
       "Explanatory Var #10 -2.508e-15   4.78e-16     -5.251      0.000   -3.45e-15   -1.57e-15\n",
       "Explanatory Var #11  7.147e-16   4.63e-16      1.544      0.123   -1.95e-16    1.62e-15\n",
       "Explanatory Var #12 -1.641e-15   3.46e-16     -4.749      0.000   -2.32e-15   -9.62e-16\n",
       "Explanatory Var #13 -1.865e-14   6.62e-15     -2.818      0.005   -3.17e-14   -5.64e-15\n",
       "Explanatory Var #14  3.592e-15   4.06e-16      8.837      0.000    2.79e-15    4.39e-15\n",
       "Explanatory Var #15 -2.078e-15   4.83e-16     -4.300      0.000   -3.03e-15   -1.13e-15\n",
       "==============================================================================\n",
       "Omnibus:                        1.684   Durbin-Watson:                   1.797\n",
       "Prob(Omnibus):                  0.431   Jarque-Bera (JB):                1.518\n",
       "Skew:                          -0.007   Prob(JB):                        0.468\n",
       "Kurtosis:                       2.707   Cond. No.                     2.53e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 2.53e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.linalg import toeplitz\n",
    "\n",
    "# Autocorrelation values you've calculated, assuming you have them\n",
    "autocorr_values = [autocorr_lag1, autocorr_lag2, autocorr_lag3]\n",
    "\n",
    "# Define the autocorrelation structure\n",
    "autocorr_structure = np.concatenate([[1.0], autocorr_values, np.zeros(418)])\n",
    "\n",
    "# Define the scaling factor (standard deviation)\n",
    "sigma = std_deviation\n",
    "\n",
    "# Create the covariance matrix\n",
    "cov_matrix = sigma**2 * toeplitz(autocorr_structure)\n",
    "\n",
    "# Use the cov_matrix in your GLS model\n",
    "gls_model = sm.GLS(y, X_updated, cov_matrix).fit()\n",
    "\n",
    "gls_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        OLS_MODEL     GLS_MODEL\n",
      "const                5.077793e-14  5.828015e-14\n",
      "Explanatory Var #1   4.100001e-16  4.709657e-16\n",
      "Explanatory Var #2   2.978755e-16  3.426139e-16\n",
      "Explanatory Var #3   5.718821e-15  6.565487e-15\n",
      "Explanatory Var #4   3.520968e-16  4.049023e-16\n",
      "Explanatory Var #5   4.126448e-16  4.746693e-16\n",
      "Explanatory Var #6   2.490277e-16  2.859467e-16\n",
      "Explanatory Var #7   1.923871e-16  2.213103e-16\n",
      "Explanatory Var #8   2.614526e-15  3.003744e-15\n",
      "Explanatory Var #9   3.342427e-16  3.842955e-16\n",
      "Explanatory Var #10  4.166230e-16  4.775899e-16\n",
      "Explanatory Var #11  4.029006e-16  4.628530e-16\n",
      "Explanatory Var #12  3.014338e-16  3.455302e-16\n",
      "Explanatory Var #13  5.774860e-15  6.617773e-15\n",
      "Explanatory Var #14  3.545322e-16  4.064257e-16\n",
      "Explanatory Var #15  4.221905e-16  4.832605e-16\n"
     ]
    }
   ],
   "source": [
    "data={'OLS_MODEL':model_updated.bse, 'GLS_MODEL':gls_model.bse}\n",
    " \n",
    "print(pd.DataFrame(data=data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.26972628,  1.68394638,  2.02626245,  2.08756512, -0.91746375,\n",
       "       -0.        ,  0.        , -0.        ,  0.        , -0.        ,\n",
       "        0.01314162,  0.        , -0.        ,  0.        , -0.03617731])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model as lm\n",
    "\n",
    "# lasso\n",
    "model_lasso = lm.Lasso(alpha=1).fit(X_train, y_train)\n",
    "model_lasso.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_lasso.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mape(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.432190198291579"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mape = calculate_mape(y_test, y_pred)\n",
    "\n",
    "mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Alpha: 0.0001\n",
      "Minimum MAPE: 0.0004248575911965283\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# create parameter grid\n",
    "param_grid = {'alpha': np.logspace(-4, 2, 100)}\n",
    "\n",
    "# create lasso model\n",
    "lasso = lm.Lasso()\n",
    "\n",
    "# create a GridSearchCV object with MAPE as the scoring metric\n",
    "grid_search = GridSearchCV(estimator=lasso, param_grid=param_grid, \n",
    "                           scoring=make_scorer(calculate_mape, greater_is_better=False), cv=10)   \n",
    "\n",
    "# Fit the GridSearchCV to your data (replace X and y with your data)\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Get the best alpha from the grid search\n",
    "best_alpha = grid_search.best_params_['alpha']\n",
    "best_mape = -grid_search.best_score_\n",
    "\n",
    "print(\"Best Alpha:\", best_alpha)\n",
    "print(\"Minimum MAPE:\", best_mape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insight: the lower the Alpha, the lower the MAPE. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>Actual Demand</th>\n",
       "      <th>Advance Demand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>112</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>107</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>103</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>91</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>85</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>84</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>85</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>79</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>81</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>134</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>86</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>89</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>111</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>114</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>118</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>163</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>193</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>143</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>144</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>202</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>158</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>160</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>144</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Month  Actual Demand  Advance Demand\n",
       "0       1            100              71\n",
       "1       2            112              30\n",
       "2       3            107              75\n",
       "3       4            103              64\n",
       "4       5             91              41\n",
       "5       6             85              51\n",
       "6       7             84              42\n",
       "7       8             85              51\n",
       "8       9             79              57\n",
       "9      10             81              49\n",
       "10     11            134             134\n",
       "11     12             86              52\n",
       "12     13             99              99\n",
       "13     14             89              56\n",
       "14     15            111              81\n",
       "15     16            114              79\n",
       "16     17            118              73\n",
       "17     18            163             163\n",
       "18     19            193             193\n",
       "19     20            143              99\n",
       "20     21            144              91\n",
       "21     22            202             202\n",
       "22     23            158             105\n",
       "23     24            160             101\n",
       "24     25            144              96"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_demand():\n",
    "    \"\"\"\n",
    "    Generates a DataFrame with the actual and advance demand\n",
    "    quantities from the example in the book.\n",
    "    \"\"\"\n",
    "\n",
    "    demand_df = pd.DataFrame()\n",
    "\n",
    "    # actual demand values\n",
    "    actual = [100, 112, 107, 103, 91,\n",
    "              85, 84, 85, 79, 81,\n",
    "              134, 86, 99, 89, 111,\n",
    "              114, 118, 163, 193, 143,\n",
    "              144, 202, 158, 160, 144]\n",
    "\n",
    "    # advance demand values\n",
    "    advance = [71, 30, 75, 64, 41,\n",
    "               51, 42, 51, 57, 49,\n",
    "               134, 52, 99, 56, 81,\n",
    "               79, 73, 163, 193, 99,\n",
    "               91, 202, 105, 101, 96]\n",
    "\n",
    "    demand_df['Month'] = np.arange(1, 26)\n",
    "    demand_df['Actual Demand'] = actual\n",
    "    demand_df['Advance Demand'] = advance\n",
    "\n",
    "    return demand_df\n",
    "\n",
    "demand_df = generate_demand()\n",
    "\n",
    "demand_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_terms(demand_df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Defines the terms used to solve the OLS and regularized models.\n",
    "    - Y : the predictor variable - current month demand\n",
    "    - X : the explanatory variables - intercept, actual demand for\n",
    "    the prior month, and advance demand for the current month\n",
    "    - L : the regularization parameter - advance demand for the\n",
    "    current month\n",
    "    \"\"\"\n",
    "\n",
    "    Y = np.array(demand_df['Actual Demand'][1:])\n",
    "\n",
    "    X = np.array([\n",
    "            np.ones_like(Y),\n",
    "            demand_df['Actual Demand'][:-1],\n",
    "            demand_df['Advance Demand'][1:]\n",
    "        ]).T\n",
    "\n",
    "    L = np.array(demand_df['Advance Demand'][1:])\n",
    "\n",
    "    return Y, X, L\n",
    "\n",
    "Y, X, L = get_terms(demand_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([112, 107, 103,  91,  85,  84,  85,  79,  81, 134,  86,  99,  89,\n",
       "        111, 114, 118, 163, 193, 143, 144, 202, 158, 160, 144], dtype=int64),\n",
       " array([[  1, 100,  30],\n",
       "        [  1, 112,  75],\n",
       "        [  1, 107,  64],\n",
       "        [  1, 103,  41],\n",
       "        [  1,  91,  51],\n",
       "        [  1,  85,  42],\n",
       "        [  1,  84,  51],\n",
       "        [  1,  85,  57],\n",
       "        [  1,  79,  49],\n",
       "        [  1,  81, 134],\n",
       "        [  1, 134,  52],\n",
       "        [  1,  86,  99],\n",
       "        [  1,  99,  56],\n",
       "        [  1,  89,  81],\n",
       "        [  1, 111,  79],\n",
       "        [  1, 114,  73],\n",
       "        [  1, 118, 163],\n",
       "        [  1, 163, 193],\n",
       "        [  1, 193,  99],\n",
       "        [  1, 143,  91],\n",
       "        [  1, 144, 202],\n",
       "        [  1, 202, 105],\n",
       "        [  1, 158, 101],\n",
       "        [  1, 160,  96]], dtype=int64),\n",
       " array([ 30,  75,  64,  41,  51,  42,  51,  57,  49, 134,  52,  99,  56,\n",
       "         81,  79,  73, 163, 193,  99,  91, 202, 105, 101,  96], dtype=int64))"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y, X, L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ols_model(Y, X):\n",
    "    \"\"\"\n",
    "    Returns the coefficients of an OLS model without applying\n",
    "    regularization. Y is the predictor variable, while X is the\n",
    "    explanatory variable.\n",
    "    \"\"\"\n",
    "\n",
    "    # calculat coefficients for ols model\n",
    "    beta = solve(X.T @ X, np.eye(3)) @ X.T @ Y\n",
    "\n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_model(Y, X, L):\n",
    "    \"\"\"\n",
    "    Returns the coeffients of an OLS model after applying regularization\n",
    "    by using advance orders as a lower bound for prediction. See the\n",
    "    equation for lambda in the book.\n",
    "    \"\"\"\n",
    "\n",
    "    lam = np.dot(2*(np.linalg.pinv(np.dot(np.dot(X,np.linalg.pinv(np.dot(X.T,X))),X.T))), L) - 2* Y\n",
    "    lam[lam < 0] = 0\n",
    "    beta_reg = np.dot(np.linalg.pinv(np.dot(X.T, X)), np.dot(X.T, Y) + 0.5*np.dot(lam, X))\n",
    "\n",
    "    return beta_reg, lam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models():\n",
    "    \"\"\"\n",
    "    Calculates and compares the accuracy of the two models presented\n",
    "    in the book. The first model is an unregularized OLS model, and the\n",
    "    second model has been regularized by using the advance orders as a\n",
    "    lower bounds for prediction.\n",
    "    \"\"\"\n",
    "\n",
    "    # generate demand quantities from example\n",
    "    demand_df = generate_demand()\n",
    "\n",
    "    # get the terms defined in the example\n",
    "    Y, X, L = get_terms(demand_df)\n",
    "\n",
    "    # calculate coefficients of the two models\n",
    "    beta = ols_model(Y, X)\n",
    "    beta_reg, lam = reg_model(Y, X, L)\n",
    "\n",
    "    # calculate the predictions\n",
    "    pred = np.dot(X, beta)\n",
    "    pred_reg = np.dot(X, beta_reg)\n",
    "    pred_reg[np.argwhere(lam > 0)] = L[np.argwhere(lam > 0)]\n",
    "\n",
    "    # calculate the accuracy (MAPE)\n",
    "    mape = calculate_mape(Y, pred)\n",
    "    mape_reg = calculate_mape(Y, pred_reg)\n",
    "\n",
    "    # add result to dataframe and round for plotting\n",
    "    result_df = pd.DataFrame()\n",
    "    result_df = result_df.append({'Model': 'OLS',\n",
    "                                  'mape': round(mape, 4)},\n",
    "                                 ignore_index=True)\n",
    "    result_df = result_df.append({'Model': 'Regularized',\n",
    "                                  'mape': round(mape_reg, 4)},\n",
    "                                 ignore_index=True)\n",
    "\n",
    "    return demand_df, result_df, lam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models():\n",
    "    \"\"\"\n",
    "    Calculates and compares the accuracy of the two models presented\n",
    "    in the book. The first model is an unregularized OLS model, and the\n",
    "    second model has been regularized by using the advance orders as a\n",
    "    lower bound for prediction.\n",
    "    \"\"\"\n",
    "\n",
    "    # generate demand quantities from example\n",
    "    demand_df = generate_demand()\n",
    "\n",
    "    # get the terms defined in the example\n",
    "    Y, X, L = get_terms(demand_df)\n",
    "\n",
    "    # calculate coefficients of the two models\n",
    "    beta = ols_model(Y, X)\n",
    "    beta_reg, lam = reg_model(Y, X, L)\n",
    "\n",
    "    # calculate the predictions\n",
    "    pred = np.dot(X, beta)\n",
    "    pred_reg = np.dot(X, beta_reg)\n",
    "    pred_reg[np.argwhere(lam > 0)] = L[np.argwhere(lam > 0)]\n",
    "\n",
    "    # calculate the accuracy (MAPE)\n",
    "    mape = calculate_mape(Y, pred)\n",
    "    mape_reg = calculate_mape(Y, pred_reg)\n",
    "\n",
    "    # create a DataFrame with the results\n",
    "    result_df = pd.DataFrame([{'Model': 'OLS', 'mape': round(mape, 4)},\n",
    "                              {'Model': 'Regularized', 'mape': round(mape_reg, 4)}])\n",
    "\n",
    "    return demand_df, result_df, lam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(    Month  Actual Demand  Advance Demand\n",
       " 0       1            100              71\n",
       " 1       2            112              30\n",
       " 2       3            107              75\n",
       " 3       4            103              64\n",
       " 4       5             91              41\n",
       " 5       6             85              51\n",
       " 6       7             84              42\n",
       " 7       8             85              51\n",
       " 8       9             79              57\n",
       " 9      10             81              49\n",
       " 10     11            134             134\n",
       " 11     12             86              52\n",
       " 12     13             99              99\n",
       " 13     14             89              56\n",
       " 14     15            111              81\n",
       " 15     16            114              79\n",
       " 16     17            118              73\n",
       " 17     18            163             163\n",
       " 18     19            193             193\n",
       " 19     20            143              99\n",
       " 20     21            144              91\n",
       " 21     22            202             202\n",
       " 22     23            158             105\n",
       " 23     24            160             101\n",
       " 24     25            144              96,\n",
       "          Model    mape\n",
       " 0          OLS  6.6713\n",
       " 1  Regularized  6.4382,\n",
       " array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 9.89075488e-12, 0.00000000e+00, 0.00000000e+00,\n",
       "        6.13908924e-12, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00]))"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_models()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
